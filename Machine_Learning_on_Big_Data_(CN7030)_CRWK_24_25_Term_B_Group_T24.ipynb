{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohansharma077/Machine-Learning-Portfolio-Exercise--Mohan-Sharma/blob/main/Machine_Learning_on_Big_Data_(CN7030)_CRWK_24_25_Term_B_Group_T24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "782e3341",
      "metadata": {
        "id": "782e3341"
      },
      "source": [
        "# Machine Learning on Big Data (CN7030) CRWK 24-25 Term B [60% weighting]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80b66c4d",
      "metadata": {
        "id": "80b66c4d"
      },
      "source": [
        " Group ID: [Group_T24]\n",
        " 1. Student 1: Mohan Sharma\n",
        " 2. Student 2: Hemlal Dulal\n",
        " 3. Student 3: Utkarsh Rimal\n",
        " 4. Student 4: Dipak Acharya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "002f9c71",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "002f9c71",
        "outputId": "b3ab479a-6aca-4e80-971d-704ff0e56f9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pyspark in c:\\users\\hemlal\\appdata\\roaming\\python\\python313\\site-packages (4.0.0)\n",
            "Requirement already satisfied: nltk in c:\\users\\hemlal\\appdata\\roaming\\python\\python313\\site-packages (3.9.1)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in c:\\users\\hemlal\\appdata\\roaming\\python\\python313\\site-packages (from pyspark) (0.10.9.9)\n",
            "Requirement already satisfied: click in c:\\users\\hemlal\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in c:\\users\\hemlal\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hemlal\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (2025.7.34)\n",
            "Requirement already satisfied: tqdm in c:\\users\\hemlal\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\hemlal\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04b8643f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04b8643f",
        "outputId": "06692f6e-a468-4dd3-f0e8-a04adfaf62fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Hemlal\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Hemlal\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f5e1a42",
      "metadata": {
        "id": "0f5e1a42",
        "outputId": "b2f78290-076d-4ef8-89f4-358603bd9601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.10.5-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Downloading contourpy-1.3.3-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.59.1-cp313-cp313-win_amd64.whl.metadata (111 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Downloading kiwisolver-1.4.9-cp313-cp313-win_amd64.whl.metadata (6.4 kB)\n",
            "Collecting numpy>=1.23 (from matplotlib)\n",
            "  Downloading numpy-2.3.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\hemlal\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (25.0)\n",
            "Collecting pillow>=8 (from matplotlib)\n",
            "  Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
            "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hemlal\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\hemlal\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading matplotlib-3.10.5-cp313-cp313-win_amd64.whl (8.1 MB)\n",
            "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
            "   ------------ --------------------------- 2.6/8.1 MB 14.2 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 5.0/8.1 MB 12.8 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 7.6/8.1 MB 12.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 8.1/8.1 MB 12.2 MB/s eta 0:00:00\n",
            "Downloading contourpy-1.3.3-cp313-cp313-win_amd64.whl (226 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.59.1-cp313-cp313-win_amd64.whl (2.3 MB)\n",
            "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.3/2.3 MB 11.8 MB/s eta 0:00:00\n",
            "Downloading kiwisolver-1.4.9-cp313-cp313-win_amd64.whl (73 kB)\n",
            "Downloading numpy-2.3.2-cp313-cp313-win_amd64.whl (12.8 MB)\n",
            "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
            "   ----- ---------------------------------- 1.8/12.8 MB 10.7 MB/s eta 0:00:02\n",
            "   ------------- -------------------------- 4.5/12.8 MB 11.3 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 7.1/12.8 MB 11.7 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 9.2/12.8 MB 11.2 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 11.8/12.8 MB 11.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 12.8/12.8 MB 10.9 MB/s eta 0:00:00\n",
            "Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
            "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
            "   --------------- ------------------------ 2.6/7.0 MB 12.6 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 6.0/7.0 MB 14.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 7.0/7.0 MB 12.2 MB/s eta 0:00:00\n",
            "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "Installing collected packages: pyparsing, pillow, numpy, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
            "\n",
            "   ---------------------------------------- 0/8 [pyparsing]\n",
            "   ---------------------------------------- 0/8 [pyparsing]\n",
            "   ----- ---------------------------------- 1/8 [pillow]\n",
            "   ----- ---------------------------------- 1/8 [pillow]\n",
            "   ----- ---------------------------------- 1/8 [pillow]\n",
            "   ----- ---------------------------------- 1/8 [pillow]\n",
            "   ----- ---------------------------------- 1/8 [pillow]\n",
            "   ----- ---------------------------------- 1/8 [pillow]\n",
            "   ----- ---------------------------------- 1/8 [pillow]\n",
            "   ----- ---------------------------------- 1/8 [pillow]\n",
            "   ----- ---------------------------------- 1/8 [pillow]\n",
            "   ----- ---------------------------------- 1/8 [pillow]\n",
            "   ----- ---------------------------------- 1/8 [pillow]\n",
            "   ----- ---------------------------------- 1/8 [pillow]\n",
            "   ----- ---------------------------------- 1/8 [pillow]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   ---------- ----------------------------- 2/8 [numpy]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   -------------------- ------------------- 4/8 [fonttools]\n",
            "   ------------------------------ --------- 6/8 [contourpy]\n",
            "   ------------------------------ --------- 6/8 [contourpy]\n",
            "   ------------------------------ --------- 6/8 [contourpy]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ----------------------------------- ---- 7/8 [matplotlib]\n",
            "   ---------------------------------------- 8/8 [matplotlib]\n",
            "\n",
            "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.1 kiwisolver-1.4.9 matplotlib-3.10.5 numpy-2.3.2 pillow-11.3.0 pyparsing-3.2.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install matplotlib\n",
        "! pip install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcd1dee6",
      "metadata": {
        "id": "bcd1dee6",
        "outputId": "71adbae2-578b-4145-9c30-3c154800717c"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'matplotlib'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, split\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "from pyspark.ml.classification import LogisticRegression, NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import expr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29962340",
      "metadata": {
        "id": "29962340"
      },
      "source": [
        "# Initiate and Configure SparkInitiate and Configure Sparkv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eb99d22",
      "metadata": {
        "id": "4eb99d22"
      },
      "outputs": [],
      "source": [
        "# Create Spark session\n",
        "spark = SparkSession.builder.appName('TextClassification').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zs0G5zN5-kvF",
      "metadata": {
        "id": "zs0G5zN5-kvF"
      },
      "outputs": [],
      "source": [
        "# Clear all cached DataFrames\n",
        "spark.catalog.clearCache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7765949",
      "metadata": {
        "id": "c7765949"
      },
      "source": [
        "# Data Loading and Preprocessing\n",
        "Dataset Description\n",
        "\n",
        "The data and information that will be used in this research is the Amazon Reviews data which will be accessed publicly on Kaggle. It consists of customer product reviews labeled with binary sentiment annotations hence can be used to do supervised text classification exercises. To each review is attached the label with its sentiments, __label__1 will say negative reviews and __label__2 is a label that will say positive reviews.\n",
        "The information is presented in the FastText format, where, each record is a combination of a label and the textual representation of the review. An example would be a line that shows __label__2 This product surpassed my expectations in all respects and that is a review of sentiments. This data set is split into two subsets namely; training set which consists of 104,537 reviews and test set which consists of 26,135 reviews. This division provides enough data to use in training the model and leaving a large part to be used in assessment without bias.\n",
        "Review samples indicate high diversity in the length of texts, writing styles, and product categories, which creates real practical problems of sentiment analysis. Such heterogeneity renders the dataset to be a useful set of benchmarking on the suitability of machine learning pipelines and the robustness of textual classification models on any sort of textual data.\n",
        "\n",
        "### Contributors:\n",
        "\n",
        "Mohan Sharma\n",
        "\n",
        "Oversaw the sentiment labels extraction of the raw text. Mohan used pyspark scripts where regular expressions to parse FastText labels and made the labels column consistent across the dataset. He ran sanity checks to make sure that every label against their respective reviews as he solidified the data then transmitted it forward to further processing.\n",
        "\n",
        "Utkarsh Rimal\n",
        "\n",
        "Concentrated on the cleanliness of the textual data before the feature extraction. Utkarsh filtered out number or blank reviews, eliminated stop words and changed all writings to lower cases to make it standardized. He justified the wiped DataFrames to make sure that no important information was lost through the preprocessing thus providing quality and noise-free text to train the models.\n",
        "\n",
        "Hemlal Dulal\n",
        "\n",
        "Visualised sample data to evaluate the length of the reviews, the range of their content and distribution of labels. Hemlal generated outputs that indicated possible anomalies and inconsistencies in the raw text, hence giving insights to correct preprocessing. His visualization contributed to the fact that the received dataset was representative and could be a basis of further machine learning activities.\n",
        "\n",
        "Dipak Acharya\n",
        "\n",
        "Helped to add the cleaned source data to the PySpark ML pipeline. Dipak ensured data compatibility data with feature extraction techniques, began to handle the data in a manner that took advantage of proper caching and worked with preparations of the data to use in training the models. His work allowed the easy transition between the preprocessing stage and model implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b52345bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b52345bc",
        "outputId": "c160b7ae-51d3-4f1b-d354-919d4ef5e316"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train DataFrame Schema:\n",
            "root\n",
            " |-- label: integer (nullable = true)\n",
            " |-- review: string (nullable = true)\n",
            "\n",
            "\n",
            "Sample Train Data:\n",
            "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|label|review                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
            "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|2    |Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^                                                                                                                                                                                                                                                                                                                                              |\n",
            "|2    |The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.                                                                                                                                                                                                                                                           |\n",
            "|2    |Amazing!: This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you've played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time's Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer's work (I haven't heard the Xenogears soundtrack, so I can't say for sure), and even if you've never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.|\n",
            "|2    |Excellent Soundtrack: I truly like this soundtrack and I enjoy video game music. I have played this game and most of the music on here I enjoy and it's truly relaxing and peaceful.On disk one. my favorites are Scars Of Time, Between Life and Death, Forest Of Illusion, Fortress of Ancient Dragons, Lost Fragment, and Drowned Valley.Disk Two: The Draggons, Galdorb - Home, Chronomantique, Prisoners of Fate, Gale, and my girlfriend likes ZelbessDisk Three: The best of the three. Garden Of God, Chronopolis, Fates, Jellyfish sea, Burning Orphange, Dragon's Prayer, Tower Of Stars, Dragon God, and Radical Dreamers - Unstealable Jewel.Overall, this is a excellent soundtrack and should be brought by those that like video game music.Xander Cross                 |\n",
            "|2    |Remember, Pull Your Jaw Off The Floor After Hearing it: If you've played the game, you know how divine the music is! Every single song tells a story of the game, it's that good! The greatest songs are without a doubt, Chrono Cross: Time's Scar, Magical Dreamers: The Wind, The Stars, and the Sea and Radical Dreamers: Unstolen Jewel. (Translation varies) This music is perfect if you ask me, the best it can be. Yasunori Mitsuda just poured his heart on and wrote it down on paper.                                                                                                                                                                                                                                                                                       |\n",
            "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Test DataFrame Schema:\n",
            "root\n",
            " |-- label: integer (nullable = true)\n",
            " |-- review: string (nullable = true)\n",
            "\n",
            "\n",
            "Sample Test Data:\n",
            "+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|label|review                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|2    |Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I'm in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life's hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"Who was that singing ?\"                                                                                                                                                                                                                                                                                           |\n",
            "|2    |One of the best game music soundtracks - for a game I didn't really play: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there's not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren't included I would still consider the collection worth it.|\n",
            "|1    |Batteries died within a year ...: I bought this charger in Jul 2003 and it worked OK for a while. The design is nice and convenient. However, after about a year, the batteries would not hold a charge. Might as well just get alkaline disposables, or look elsewhere for a charger that comes with batteries that have better staying power.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "|2    |works fine, but Maha Energy is better: Check out Maha Energy's website. Their Powerex MH-C204F charger works in 100 minutes for rapid charge, with option for slower charge (better for batteries). And they have 2200 mAh batteries.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
            "|2    |Great for the non-audiophile: Reviewed quite a bit of the combo players and was hesitant due to unfavorable reviews and size of machines. I am weaning off my VHS collection, but don't want to replace them with DVD's. This unit is well built, easy to setup and resolution and special effects (no progressive scan for HDTV owners) suitable for many people looking for a versatile product.Cons- No universal remote.                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
            "+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Read the train and test files\n",
        "train_df = spark.read.text(\"train.ft.txt\")\n",
        "test_df = spark.read.text(\"test.ft.txt\")\n",
        "\n",
        "# Split the text into label and review\n",
        "from pyspark.sql.functions import when, length, split, col, regexp_extract\n",
        "\n",
        "# Process train data to extract label and review\n",
        "train_df = train_df.select(\n",
        "    regexp_extract(col(\"value\"), r\"__label__(\\d+)\", 1).cast(\"integer\").alias(\"label\"),\n",
        "    regexp_extract(col(\"value\"), r\"__label__\\d+\\s+(.*)\", 1).alias(\"review\")\n",
        ")\n",
        "train_df = train_df.na.drop()  # Remove any rows with null values\n",
        "\n",
        "# Process test data to extract label and review\n",
        "test_df = test_df.select(\n",
        "    regexp_extract(col(\"value\"), r\"__label__(\\d+)\", 1).cast(\"integer\").alias(\"label\"),\n",
        "    regexp_extract(col(\"value\"), r\"__label__\\d+\\s+(.*)\", 1).alias(\"review\")\n",
        ")\n",
        "test_df = test_df.na.drop()  # Remove any rows with null values\n",
        "\n",
        "# Print sample data to verify format\n",
        "print(\"Train DataFrame Schema:\")\n",
        "train_df.printSchema()\n",
        "print(\"\\nSample Train Data:\")\n",
        "train_df.show(5, truncate=False)\n",
        "print(\"\\nTest DataFrame Schema:\")\n",
        "test_df.printSchema()\n",
        "print(\"\\nSample Test Data:\")\n",
        "test_df.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42053f76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42053f76",
        "outputId": "3cf89320-1aee-410d-835b-73335e18d4bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 5 lines of raw training data:\n",
            "__label__2 Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\n",
            "__label__2 The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\n",
            "__label__2 Amazing!: This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you've played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time's Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer's work (I haven't heard the Xenogears soundtrack, so I can't say for sure), and even if you've never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.\n",
            "__label__2 Excellent Soundtrack: I truly like this soundtrack and I enjoy video game music. I have played this game and most of the music on here I enjoy and it's truly relaxing and peaceful.On disk one. my favorites are Scars Of Time, Between Life and Death, Forest Of Illusion, Fortress of Ancient Dragons, Lost Fragment, and Drowned Valley.Disk Two: The Draggons, Galdorb - Home, Chronomantique, Prisoners of Fate, Gale, and my girlfriend likes ZelbessDisk Three: The best of the three. Garden Of God, Chronopolis, Fates, Jellyfish sea, Burning Orphange, Dragon's Prayer, Tower Of Stars, Dragon God, and Radical Dreamers - Unstealable Jewel.Overall, this is a excellent soundtrack and should be brought by those that like video game music.Xander Cross\n",
            "__label__2 Remember, Pull Your Jaw Off The Floor After Hearing it: If you've played the game, you know how divine the music is! Every single song tells a story of the game, it's that good! The greatest songs are without a doubt, Chrono Cross: Time's Scar, Magical Dreamers: The Wind, The Stars, and the Sea and Radical Dreamers: Unstolen Jewel. (Translation varies) This music is perfect if you ask me, the best it can be. Yasunori Mitsuda just poured his heart on and wrote it down on paper.\n"
          ]
        }
      ],
      "source": [
        "# Check raw data format\n",
        "with open(\"train.ft.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    print(\"First 5 lines of raw training data:\")\n",
        "    for i, line in enumerate(f):\n",
        "        if i < 5:\n",
        "            print(line.strip())\n",
        "        else:\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b7ded79",
      "metadata": {
        "id": "4b7ded79"
      },
      "source": [
        "Data Cleaning and Extraction\n",
        "\n",
        "PySpark is used to do data cleaning and extraction using the distributed processing power. Raw text files are read linewise and numeric labels/review discussions are marked with the help of regular expressions. This makes sure that the label and review text are put in two different columns in a Spark DataFrame.\n",
        "Elements of reviews with null or empty values of the text are withdrawn as a way to guarantee quality of data and hence error in training of the model. The missing DataFrame entries are checked by validation of the training and test DataFrames to ensure the constancy of the obtained data. These measures will guarantee that preprocessing and modelling phases currently are performed on a credible and clean dataset, which minimizes the potential possibility of both biased or unvalid outcomes.\n",
        "\n",
        "Text Preprocessing Pipeline\n",
        "\n",
        "The pipeline to preprocess text is used converting raw review words into the numerical representation that can be used by machine learning approach. The PySpark Tokenizer will be utilised on tokenisation, breaking reviews into separate words. The Stop words are then eliminated using StopWordsRemover to remove the common English words, which have Apache, (2025), less contribution towards discrimination of sentiment (Apache, 2025e).\n",
        "CountVectorizer is used to perform feature extraction on the tokenised text and describes Apache, (2025a) word frequencies as numerical vectors. This generates a sparse matrix of high dimensions Apache, (2025b), that work with both Logistic Regression and Naive Bayes classifiers. This allows an increase in computational efficiency, by caching the resulting training and test DataFrames in memory, thus making quicker available in model training and evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a90a5ca7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a90a5ca7",
        "outputId": "53d9093f-40b8-4060-c8de-dfe72424b3bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing training data...\n",
            "Initial count: 90518\n",
            "After tokenization count: 90518\n",
            "After stopwords removal count: 90518\n",
            "After CountVectorizer transformation count: 90518\n",
            "\n",
            "Processing test data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DataFrame[label: int, review: string, words: array<string>, filtered_words: array<string>, features: vector]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create text processing pipeline with error handling\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import ArrayType, StringType\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "\n",
        "# Create text processing pipeline\n",
        "tokenizer = Tokenizer(inputCol=\"review\", outputCol=\"words\")\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
        "# Create CountVectorizer instead of HashingTF and IDF\n",
        "countVectorizer = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"features\", vocabSize=10000)\n",
        "\n",
        "\n",
        "# Process train data with validation checks\n",
        "print(\"Processing training data...\")\n",
        "print(\"Initial count:\", train_df.count())\n",
        "\n",
        "train_df = tokenizer.transform(train_df)\n",
        "print(\"After tokenization count:\", train_df.count())\n",
        "\n",
        "train_df = remover.transform(train_df)\n",
        "print(\"After stopwords removal count:\", train_df.count())\n",
        "\n",
        "# Fit CountVectorizer model\n",
        "cv_model = countVectorizer.fit(train_df)\n",
        "train_df = cv_model.transform(train_df)\n",
        "print(\"After CountVectorizer transformation count:\", train_df.count())\n",
        "\n",
        "# Cache the DataFrame to improve performance\n",
        "train_df.cache()\n",
        "\n",
        "\n",
        "# Process test data\n",
        "print(\"\\nProcessing test data...\")\n",
        "test_df = tokenizer.transform(test_df)\n",
        "test_df = remover.transform(test_df)\n",
        "test_df = cv_model.transform(test_df)\n",
        "\n",
        "# Cache the final DataFrames\n",
        "train_df.cache()\n",
        "test_df.cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61695fa4",
      "metadata": {
        "id": "61695fa4"
      },
      "source": [
        "# Model Selection and Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f66dbfd9",
      "metadata": {
        "id": "f66dbfd9"
      },
      "source": [
        "Logistic Regression is a linear probabilistic classifier which makes predictions concerning the likelihood that the categorical outcome is binary. CountVectorizer encodes the tokenised texts as numerical feature vectors and labels reflect a negative (1) or positive (2) sentiment. This model would be trained on training set, and tested on test set. The metrics of the evaluation comprise accuracy, precision, recall, and F1-score. Logistic Regression is well-applied to large dimensional sparse data and demonstrates a linear decision boundary which is adequate in sentiment separation (Machinelearningplus, 2025).\n",
        "Naive Bayes, known as a probabilistic classifier, that assumes feature independence. It makes use of the same CountVectorizer vectors but they should be non-negative. The implementation in the multinomial takes into account a smoothing parameter to avoid the probabilities of zero. Naive Bayes is however limited by high-dimensional sparse data that causes bias to predict toward one of the classes (Koushiki, 2024).\n",
        "\n",
        "Evaluation Metrics\n",
        "\n",
        "The evaluation is based on the precision, recall, and accuracy along with F1-score. Weighted measures take into consideration class imbalance. Confusion matrices help to get the detailed information about the errors during the classification indicating the true positives, true negatives, false positives, and false negatives. This enables one to have a straightforward comparison between Logistic Regression and Naive Bayes, both in terms of advantages and weaknesses as relates to sentiment analysis (Ayan, 2024).\n",
        "\n",
        "#### Contributors:\n",
        "\n",
        "Dipak Acharya\n",
        "\n",
        "Organized the adoption and adoption of the Logistic Regression model. He employed TF-IDF feature vectors as prepared in preprocessing to train the model, as well as pre-set the model parameters, and made predictions against the test sets. Dipak justified indication metrics those were Accuracy, Precision, Recall, and F1-score besides it assisted the team in translating the outcomes in terms of sentiment categorization.\n",
        "\n",
        "Utkarsh Rimal\n",
        "\n",
        "Conducted the use of the Naive Bayes classifier. He used CountVectorizer features to train the model, fit, and predictions, and high-dimensional and sparse data and the algorithm independence assumptions were also concerned. Utkarsh was able to analyse the poor evaluation measures and proposed enhancements to the preprocessing and features engineering.\n",
        "\n",
        "Mohan Sharma\n",
        "\n",
        "Supervised the coordination of preprocessing with modelling. He saw to it that there was smooth exchange of data in terms of tokenization and removing stop-words, feature extraction and the training of the model. Mohan also debugged pipeline, checked intermediate output and validated that result remains the same when Logistic Regression as well as Naive Bayes models are used (in PySpark MLlib).\n",
        "\n",
        "Hemlal Dulal\n",
        "\n",
        "Guided analysis of model and visualization. He also displayed confusion matrices, visualised measures of performance, and emphasised error types, including the false positive and false negative. Hemlal liaised with Dipak and Utkarsh in data interpretation and supplied information that was used in guiding practical suggestions and comparative study on the two models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6239d78c",
      "metadata": {
        "id": "6239d78c"
      },
      "outputs": [],
      "source": [
        "# Train Logistic Regression model\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "lr_model = lr.fit(train_df)\n",
        "\n",
        "# Make predictions on test data\n",
        "lr_predictions = lr_model.transform(test_df)\n",
        "\n",
        "# Evaluate Logistic Regression model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "lr_accuracy = evaluator.setMetricName(\"accuracy\").evaluate(lr_predictions)\n",
        "lr_precision = evaluator.setMetricName(\"weightedPrecision\").evaluate(lr_predictions)\n",
        "lr_recall = evaluator.setMetricName(\"weightedRecall\").evaluate(lr_predictions)\n",
        "lr_f1 = evaluator.setMetricName(\"f1\").evaluate(lr_predictions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9aea6ea",
      "metadata": {
        "id": "c9aea6ea"
      },
      "source": [
        "Logistic Regression Performance\n",
        "\n",
        "The Logistic Regression model showed high results in the test data with an accuracy rate of 0.8519, a precision rate of 0.8520, recall rate of 0.8519 and F1 score value of 0.8519. These findings show that the model shows consistency in differentiating the positive and negative reviews.\n",
        "What can be gained is the confusion matrix: with 47,250 actual negative reviews, 39,692 were correctly categorised, and 7,558 incorrectly categorised as positive. In the case of positive reviews 41,886 of 48,509 were classified correctly whereas there were 6,623 that were classified as negative reviews. This provides an equal performance between the two classes with true positive rate of 0.864 and true negative rate of 0.839.\n",
        "Error analysis shows that false positives are usually reviews that have mixed sentiments or have negative cues that are just nuanced whereas false negatives usually contain reviews that have nuanced positive cues or rather domain-specific language. The probabilistic nature of the features in the model is in a position to process high dimension sparse characteristics of Count and identifying extent features of Vectorizer, with consistent classifications throughout the pool.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acb7bf13",
      "metadata": {
        "id": "acb7bf13"
      },
      "outputs": [],
      "source": [
        "# Train Naive Bayes model\n",
        "nb = NaiveBayes(featuresCol=\"features\", labelCol=\"label\")\n",
        "nb_model = nb.fit(train_df)\n",
        "\n",
        "# Make predictions on test data\n",
        "nb_predictions = nb_model.transform(test_df)\n",
        "\n",
        "# Evaluate Naive Bayes model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "nb_accuracy = evaluator.setMetricName(\"accuracy\").evaluate(nb_predictions)\n",
        "nb_precision = evaluator.setMetricName(\"weightedPrecision\").evaluate(nb_predictions)\n",
        "nb_recall = evaluator.setMetricName(\"weightedRecall\").evaluate(nb_predictions)\n",
        "nb_f1 = evaluator.setMetricName(\"f1\").evaluate(nb_predictions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "767a7a19",
      "metadata": {
        "id": "767a7a19"
      },
      "source": [
        "Naive Bayes Performance\n",
        "\n",
        "On the contrary, the Naive Bayes performed dismally, giving an accuracy, precision, recall and F1-score of 0.0776, 0.0753, 0.0776 and 0.0765 respectively. In the confusion matrix, there is a large bias in one class, meaning that predictions were wrong in most cases.\n",
        "There are a number of factors that can explain this under performance. CountVectorizer or TF-IDF feature vectors can break the independence assumption needed by Naive Bayes and the sparse vectors in high dimensions exacerbates this problem. Also, CountVectorizer creates non-and negatively based features which are not compatible with the multinomial Naive Bayes assumptions and thus the single-class model is favoured by the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83b89f84",
      "metadata": {
        "id": "83b89f84"
      },
      "source": [
        "# Model Evaluation and Accuracy Calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72a001ca",
      "metadata": {
        "id": "72a001ca"
      },
      "source": [
        "The Evaluation step consisted of calculating the standard classification metrics of both the Logistic Regression and Naive Bayes models. The accuracy, precision, recall, and F1-score were determined in PySpark by using MulticlassClassificationEvaluator. Confusion matrices were also created so as to bring about an in-depth analysis of true positives, true negatives, false positives and false negatives of the models. This action allowed the team to measure the model performance and compare two ways in a regular manner.\n",
        "\n",
        "### Contributors:\n",
        "Mohan Sharma\n",
        "\n",
        "Headed the analysis of the Logistic Regression model. Mohan used the PySpark programs to compute Accuracy, Precision, Recall and F1-score. He was checking what had been calculated as metrics and output was compared. Also, he has given an elaborate account of the performance of Logistic Regression in the large-scale Amazon Reviews dataset, by deciding on the reliability of the model along with classification strengths.\n",
        "\n",
        "Dipak Acharya\n",
        "\n",
        "In charge of the examination of the Naive Bayes model. Dipak calculated the identical metrics with PySpark and paid attention to overcoming such challenges as the sparse features produced by CountVectorizer. He tested this feature on Naive Bayes poor performance by finding out contributory factors, which include feature sparsity and independence assumptions that facilitated the comparative analysis by the team on the two models.\n",
        "\n",
        "Hemlal Dulal\n",
        "\n",
        "Coordinated the construction and analysis of confusion matrices of the two models. Hemlal visualized misclassification patterns, analysed false positives and false negatives, and included deep analytical insights regarding the behaviour of the model. These observations helped the team learn the mistakes of classification and make suggestions concerning practical implementation.\n",
        "\n",
        "Utkarsh Rimal\n",
        "\n",
        "Aided the calculation and verification of metrics of both models. Utkarsh compared assessment scripts, made sure the performance indicators were consistent across the scoring, and cooperated in discussing inconsistency in outputs. His work led to preserving the precision and the trustworthiness of the analysis procedure throughout the data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46eafb2f",
      "metadata": {
        "id": "46eafb2f"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression Evaluation\n",
        "print(\"Logistic Regression Results:\")\n",
        "print(f\"Accuracy: {lr_accuracy:.4f}\")\n",
        "print(f\"Precision: {lr_precision:.4f}\")\n",
        "print(f\"Recall: {lr_recall:.4f}\")\n",
        "print(f\"F1 Score: {lr_f1:.4f}\")\n",
        "\n",
        "# Naive Bayes Evaluation\n",
        "print(\"Naive Bayes Results (with CountVectorizer):\")\n",
        "print(f\"Accuracy: {nb_accuracy:.4f}\")\n",
        "print(f\"Precision: {nb_precision:.4f}\")\n",
        "print(f\"Recall: {nb_recall:.4f}\")\n",
        "print(f\"F1 Score: {nb_f1:.4f}\")\n",
        "\n",
        "# Display confusion matrices\n",
        "def display_confusion_matrix(predictions, model_name):\n",
        "    confusion_matrix = predictions.groupBy(\"label\", \"prediction\").count().orderBy(\"label\", \"prediction\")\n",
        "    print(f\"\\nConfusion Matrix for {model_name}:\")\n",
        "    confusion_matrix.show()\n",
        "\n",
        "# Display confusion matrices for both models\n",
        "display_confusion_matrix(lr_predictions, \"Logistic Regression\")\n",
        "display_confusion_matrix(nb_predictions, \"Naive Bayes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f28894d8",
      "metadata": {
        "id": "f28894d8"
      },
      "source": [
        "# Results Visualization\n",
        "\n",
        "In comparing the two models, the Logistic Regression obviously excels well over the Naive Bayes under all the evaluation indices. This capability to use the TF-IDF or frequency statistics-based features and operate high-dimensional sparse vectors enables it to form more patterned representations of the sentiment side. Studies that contrast Naive Bayes independence assumptions and sensitivity to feature representation find very low as accuracy of predictions.\n",
        "In the same sentiment analysis task, Logistic Regression is advised especially in CountVectorizer or TF-IDF features since it offers answer results on a probabilistic manner and balanced classification besides scale-ability in distributed environment such as PySpark. Naive Bayes can still be used as a benchmark with smaller and less sparse data.\n",
        "\n",
        "Hemlal Dulal\n",
        "\n",
        "Plotted bar graphs and graphical displays statistics of model assessment. Hemlal displayed Accuracy, Precision, Recall and F1-score of both the Logistic Regression and Naive Bayes so that the team could compare the model performance in a snap. His plots brought out performance patterns and were used to base on the discussion of the models selection and its practical consequences.\n",
        "\n",
        "Utkarsh Rimal\n",
        "\n",
        "Came up with comparative tables of evaluation measurements of the two models. Utkarsh aligned metrics in rows and it was easy to see performance differences. His tables were properly labelled, easy to read, and could be included in the report and presentation to ensure that the stakeholders grasped the performance of the models within a short time.\n",
        "\n",
        "Mohan Sharma\n",
        "\n",
        "Was responsible in displaying and performing analysis of confusion matrices of the two models. Mohan used true positive, true negative, false positive and false negative counts, and depicted them using a clear tabulated format. This visualisation helped the team to understand its weak areas and could discuss strengths and weaknesses of models.\n",
        "\n",
        "Dipak Acharya\n",
        "\n",
        "Helped to unite visualization results and confirm that the metrics were the same betweenicle and table. Dipak made sure that every visualization is relevant to the underlying data used to perform the evaluations, looked into it in relation to the calculations made to assess the metrics, and would use the team to analyze findings, which would be reflected in the report and presentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4feef4fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "4feef4fb",
        "outputId": "9c29810f-4394-438b-817f-a06f23f0727b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Confusion Matrix for Logistic Regression:\n",
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|    1|       1.0|39692|\n",
            "|    1|       2.0| 7558|\n",
            "|    2|       1.0| 6623|\n",
            "|    2|       2.0|41886|\n",
            "+-----+----------+-----+\n",
            "\n",
            "\n",
            "Confusion Matrix for Naive Bayes:\n",
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|    1|       0.0|39816|\n",
            "|    1|       1.0| 7434|\n",
            "|    2|       0.0| 7245|\n",
            "|    2|       1.0|41264|\n",
            "+-----+----------+-----+\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGzCAYAAADT4Tb9AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVpFJREFUeJzt3Xtcjvf/B/DXfafuu7NDR0mhViJlpZbDsokc5zQapoR8N2I0QzZymOUwyfm0wmwm59kYI9qGhmWMjZBTTKWNIpS6P78//LrnVtFJd11ez8fjftDn+lzX9b6uq6teXdfnum+ZEEKAiIiISCLk2i6AiIiIqDIx3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEFVzMpkM06ZN03YZFbZ+/Xo4OztDV1cXtWvX1nY5RVy5cgUymQxr164t87wJCQmQyWRISEio9LoqYt68eWjcuDF0dHTg7u6u7XKIqgzDDVV7KSkp+N///ofGjRtDqVTCxMQEbdq0wcKFC/HgwQNtl0elcO7cOQwZMgRNmjTB6tWrsWrVqhL7Tps2DTKZDHK5HKmpqUWmZ2dnQ19fHzKZDKGhoS+y7Eq3du1ayGQy9UupVOKVV15BaGgo0tPTK3VdP/74IyZMmIA2bdpgzZo1+Oyzzyp1+UTVWS1tF0D0LLt27UK/fv2gUCgQGBiI5s2bIy8vD4cOHcJHH32EP//885m/KKXgwYMHqFWrZp+qCQkJUKlUWLhwIRwcHEo1j0KhwDfffIMJEyZotG/btu1FlFilZsyYgUaNGuHhw4c4dOgQli9fjt27d+PMmTMwMDColHUcOHAAcrkcMTEx0NPTq5RlEtUUNfsnJkna5cuX8c4778DOzg4HDhyAtbW1etqoUaNw8eJF7Nq1S4sVvjgqlQp5eXlQKpVQKpXaLqfCMjIyAKBMt6O6du1abLjZsGEDunXrhq1bt1ZmiVWqS5cu8PT0BAAMHz4c9erVQ1RUFL799lsMGDCgQsu+f/8+DAwMkJGRAX19/UoLNkIIPHz4EPr6+pWyPKIXibelqNqaO3cu7t27h5iYGI1gU8jBwQEffPCB+uv8/HzMnDkTTZo0gUKhgL29PSZPnozc3FyN+ezt7dG9e3ckJCTA09MT+vr6cHV1VY+X2LZtG1xdXaFUKuHh4YHff/9dY/4hQ4bAyMgIly5dgr+/PwwNDVG/fn3MmDEDQgiNvp9//jlat26NevXqQV9fHx4eHtiyZUuRbSm8xfL111+jWbNmUCgU2LNnj3rak2Nu7t69i7Fjx8Le3h4KhQIWFhbo2LEjTpw4obHMzZs3w8PDA/r6+jAzM8O7776LGzduFLstN27cQK9evWBkZARzc3OMHz8eBQUFJRwZTcuWLVPXXL9+fYwaNQp37tzR2N8REREAAHNz81KPIRo4cCBOnjyJc+fOqdvS0tJw4MABDBw4sNh5MjIyMGzYMFhaWkKpVMLNzQ3r1q0r0u/OnTsYMmQITE1NUbt2bQQFBWnU/KRz587h7bffRt26daFUKuHp6YmdO3c+t/6yePPNNwE8DvSFvvrqK/Xxq1u3Lt55550it+nat2+P5s2bIykpCa+//joMDAwwefJkyGQyrFmzBjk5OepbYIVjicp6nuzdu1d9nqxcuVI9vmjTpk2YPn06bGxsYGxsjLfffhtZWVnIzc3F2LFjYWFhASMjIwQHBxdZ9po1a/Dmm2/CwsICCoUCLi4uWL58eZH9UljDoUOH4OXlBaVSicaNG+PLL78s0vfOnTsYN26c+rxo0KABAgMDkZmZqe6Tm5uLiIgIODg4QKFQwNbWFhMmTChSH0mAIKqmbGxsROPGjUvdPygoSAAQb7/9tli6dKkIDAwUAESvXr00+tnZ2QknJydhbW0tpk2bJhYsWCBsbGyEkZGR+Oqrr0TDhg3F7NmzxezZs4WpqalwcHAQBQUFGutRKpXC0dFRDB48WCxZskR0795dABBTpkzRWFeDBg3EyJEjxZIlS0RUVJTw8vISAMT333+v0Q+AaNq0qTA3NxfTp08XS5cuFb///rt6WkREhLrvwIEDhZ6enggLCxNffPGFmDNnjujRo4f46quv1H3WrFkjAIhWrVqJBQsWiEmTJgl9fX1hb28vbt++XWRbmjVrJoYOHSqWL18u+vbtKwCIZcuWPXefR0RECADCz89PLF68WISGhgodHR3RqlUrkZeXJ4QQYvv27aJ3794CgFi+fLlYv369OHXq1HOXmZGRIRo0aKCxT6Ojo4Wpqal4+PChACBGjRqlnnb//n3RtGlToaurK8aNGycWLVok2rVrJwCI6OhodT+VSiVef/11IZfLxciRI8XixYvFm2++KVq0aCEAiDVr1qj7njlzRpiamgoXFxcxZ84csWTJEvH6668LmUwmtm3bpu538OBBAUAcPHjwmfur8LgcP35co33hwoUCgFixYoUQQohPP/1UyGQyERAQIJYtWyamT58uzMzMihw/X19fYWVlJczNzcXo0aPFypUrxY4dO8T69etFu3bthEKhEOvXrxfr168XKSkpQoiynScODg6iTp06YtKkSWLFihXi4MGD6m11d3cXPj4+YtGiRWLMmDFCJpOJd955RwwcOFB06dJFLF26VAwePFgAENOnT9dYdqtWrcSQIUPEggULxOLFi0WnTp0EALFkyZIiNTg5OQlLS0sxefJksWTJEvHqq68KmUwmzpw5o+539+5d0bx5c6GjoyNCQkLE8uXLxcyZM0WrVq3U51FBQYHo1KmTMDAwEGPHjhUrV64UoaGholatWqJnz57PPG5U8zDcULWUlZUlAJT6h87JkycFADF8+HCN9vHjxwsA4sCBA+o2Ozs7AUAcOXJE3bZ3714BQOjr64urV6+q21euXFnkl1bhL4fRo0er21QqlejWrZvQ09MTt27dUrffv39fo568vDzRvHlz8eabb2q0AxByuVz8+eefRbbt6XBjamqq8Uv9aXl5ecLCwkI0b95cPHjwQN3+/fffCwBi6tSpRbZlxowZGsto2bKl8PDwKHEdQgiRkZEh9PT0RKdOnTTC35IlSwQAERsbq24rDCxP7puSPNl3/PjxwsHBQT2tVatWIjg4WAghioSb6OhoAUAj5OXl5QkfHx9hZGQksrOzhRBC7NixQwAQc+fOVffLz89XB6Enw02HDh2Eq6urePjwobpNpVKJ1q1bC0dHR3VbWcPN/v37xa1bt0RqaqrYuHGjqFevntDX1xfXr18XV65cETo6OmLWrFka854+fVrUqlVLo93X11cjFD0pKChIGBoaarSV5zzZs2ePRt/CbW3evLk6wAohxIABA4RMJhNdunTR6O/j4yPs7Ow02p4+L4QQwt/fv8gfM4U1/Pzzz+q2jIwMoVAoxIcffqhumzp1qgCgETgLqVQqIYQQ69evF3K5XPzyyy8a01esWCEAiMOHDxeZl2ou3paiaik7OxsAYGxsXKr+u3fvBgCEhYVptH/44YcAUGRsjouLC3x8fNRfe3t7A3h8e6Bhw4ZF2i9dulRknU8+qVN4WykvLw/79+9Xtz85PuH27dvIyspCu3btitxCAgBfX1+4uLg8Z0sfj1s5evQo/v7772Kn//bbb8jIyMDIkSM1xut069YNzs7OxY5Teu+99zS+bteuXbHb/KT9+/cjLy8PY8eOhVz+34+SkJAQmJiYVMp4qIEDB+LixYs4fvy4+t+Sbknt3r0bVlZWGmNWdHV1MWbMGNy7dw8//fSTul+tWrXw/vvvq/vp6Ohg9OjRGsv7999/ceDAAfTv3x93795FZmYmMjMz8c8//8Df3x8XLlwocpuvtPz8/GBubg5bW1u88847MDIywvbt22FjY4Nt27ZBpVKhf//+6nVmZmbCysoKjo6OOHjwoMayFAoFgoODS7Xesp4njRo1gr+/f7HLCgwMhK6urvprb29vCCEwdOhQjX7e3t5ITU1Ffn6+uu3J8yIrKwuZmZnw9fXFpUuXkJWVpTG/i4sL2rVrp/7a3NwcTk5OGt+fW7duhZubG3r37l2kTplMBuDxbdqmTZvC2dlZY78W3hJ8er9SzcYBxVQtmZiYAHg8vqQ0rl69CrlcXuRJHCsrK9SuXRtXr17VaH8ywACAqakpAMDW1rbY9tu3b2u0y+VyNG7cWKPtlVdeAfD4/VIKff/99/j0009x8uRJjfv6hT9wn9SoUaMSt+9Jc+fORVBQEGxtbeHh4YGuXbsiMDBQXU/htjo5ORWZ19nZGYcOHdJoUyqVMDc312irU6dOkW1+Wknr0dPTQ+PGjYvs8/Jo2bIlnJ2dsWHDBtSuXRtWVlbqX0bF1ePo6KgRtACgadOmGvVevXoV1tbWMDIy0uj39HZcvHgRQghMmTIFU6ZMKXadGRkZsLGxKfN2LV26FK+88gpq1aoFS0tLODk5qeu+cOEChBBwdHQsdt4nAwUA2NjYlHrQcFnPk2d9T5blHFKpVMjKykK9evUAAIcPH0ZERAQSExNx//59jf5ZWVnqZRW3HqDo92dKSgr69u1bYq3A4/169uzZIt/rhQoHvZM0MNxQtWRiYoL69evjzJkzZZqvuNBQHB0dnTK1i6cGCpfGL7/8grfeeguvv/46li1bBmtra+jq6mLNmjXYsGFDkf6lfQqlf//+aNeuHbZv344ff/wR8+bNw5w5c7Bt2zZ06dKlzHWWtM3VxcCBA7F8+XIYGxsjICCgSHh5UVQqFQBg/PjxJV69KO1j7U/z8vJSPy1V3HplMhl++OGHYo/N06GsPE8vlfY8edayy3sOpaSkoEOHDnB2dkZUVBRsbW2hp6eH3bt3Y8GCBer9XtrllZZKpYKrqyuioqKKnf50KKOajeGGqq3u3btj1apVSExM1LiFVBw7OzuoVCpcuHBB/Zc6AKSnp+POnTuws7Or1NpUKhUuXbqkvloDAOfPnwfw+AkP4PGlcqVSib1790KhUKj7rVmzpsLrt7a2xsiRIzFy5EhkZGTg1VdfxaxZs9ClSxf1tiYnJxe5ypGcnFxp++LJ9Tx5FSsvLw+XL1+Gn59fpaxn4MCBmDp1Km7evIn169c/s54//vgDKpVKIwAVPm1VWK+dnR3i4+Nx7949jaCQnJyssbzCbdLV1a20bSmNJk2aQAiBRo0aaXx/VYaqPk+K89133yE3Nxc7d+7UuCpTkdtCTZo0ee4fQk2aNMGpU6fQoUOHUoc7qrk45oaqrQkTJsDQ0BDDhw8v9t1bU1JSsHDhQgCP3xMFAKKjozX6FP6V1q1bt0qvb8mSJer/CyGwZMkS6OrqokOHDgAe/8Upk8k0Hqm+cuUKduzYUe51FhQUFBmTYGFhgfr166tve3l6esLCwgIrVqzQuBX2ww8/4OzZs5W2L/z8/KCnp4dFixZp/BUdExODrKysSltPkyZNEB0djcjISHh5eZXYr2vXrkhLS0NcXJy6LT8/H4sXL4aRkRF8fX3V/fLz8zUePS4oKMDixYs1lmdhYYH27dtj5cqVuHnzZpH13bp1q6KbVqw+ffpAR0cH06dPL3J1QgiBf/75p9zL1sZ58rTCKzFPbltWVlaFQn/fvn1x6tQpbN++vci0wvX0798fN27cwOrVq4v0efDgAXJycsq9fqp+eOWGqq0mTZpgw4YNCAgIQNOmTTXeofjIkSPYvHkzhgwZAgBwc3NDUFAQVq1ahTt37sDX1xfHjh3DunXr0KtXL7zxxhuVWptSqcSePXsQFBQEb29v/PDDD9i1axcmT56svqffrVs3REVFoXPnzhg4cCAyMjKwdOlSODg44I8//ijXeu/evYsGDRrg7bffhpubG4yMjLB//34cP34c8+fPB/D4SsOcOXMQHBwMX19fDBgwAOnp6Vi4cCHs7e0xbty4StkH5ubmCA8Px/Tp09G5c2e89dZbSE5OxrJly9CqVSu8++67lbIeABrvZ1SSESNGYOXKlRgyZAiSkpJgb2+PLVu24PDhw4iOjlYPTu/RowfatGmDSZMm4cqVK3BxccG2bduKhEbg8diYtm3bwtXVFSEhIWjcuDHS09ORmJiI69ev49SpU5W2jYWaNGmCTz/9FOHh4bhy5Qp69eoFY2NjXL58Gdu3b8eIESMwfvz4ci27qs+T4nTq1Al6enro0aMH/ve//+HevXtYvXo1LCwsig2RpfHRRx9hy5Yt6NevH4YOHQoPDw/8+++/2LlzJ1asWAE3NzcMHjwYmzZtwnvvvYeDBw+iTZs2KCgowLlz57Bp0yb1+/mQRGjlGS2iMjh//rwICQkR9vb2Qk9PTxgbG4s2bdqIxYsXazyi++jRIzF9+nTRqFEjoaurK2xtbUV4eLhGHyEeP17arVu3IuvBU48WCyHE5cuXBQAxb948dVvhI7YpKSnq982wtLQUERERGo9ECyFETEyMcHR0FAqFQjg7O4s1a9aoH3V+3rqfnFb4KHhubq746KOPhJubmzA2NhaGhobCzc2t2PekiYuLEy1bthQKhULUrVtXDBo0SFy/fl2jT3GPCwshiq2xJEuWLBHOzs5CV1dXWFpaivfff1/jvVieXF5ZHwV/luL2WXp6uggODhZmZmZCT09PuLq6ajzaXeiff/4RgwcPFiYmJsLU1FQMHjxY/P7770UeBRdCiJSUFBEYGCisrKyErq6usLGxEd27dxdbtmxR96no+9wUZ+vWraJt27bC0NBQGBoaCmdnZzFq1CiRnJys7uPr6yuaNWtW7PwlHduKnieF27p58+ZSbVtxx3Pnzp2iRYsWQqlUCnt7ezFnzhwRGxsrAIjLly8/twZfX1/h6+ur0fbPP/+I0NBQYWNjI/T09ESDBg1EUFCQyMzMVPfJy8sTc+bMEc2aNRMKhULUqVNHeHh4iOnTp4usrKyiO5FqLJkQ5RgpSfQSGzJkCLZs2YJ79+5puxQiIioGx9wQERGRpDDcEBERkaQw3BAREZGkcMwNERERSQqv3BAREZGkMNwQERGRpLx0b+KnUqnw999/w9jYmG/BTUREVEMIIXD37l3Ur1//uZ8x99KFm7///psfkEZERFRDpaamokGDBs/s89KFm8K3YE9NTYWJiYmWqyEiIqLSyM7Ohq2trfr3+LO8dOGm8FaUiYkJww0REVENU5ohJRxQTERERJLCcENERESSwnBDREREkvLSjbkhIpIKIQTy8/NRUFCg7VKIKoWuri50dHQqvByGGyKiGigvLw83b97E/fv3tV0KUaWRyWRo0KABjIyMKrQchhsiohpGpVLh8uXL0NHRQf369aGnp8c3JaUaTwiBW7du4fr163B0dKzQFRyGGyKiGiYvLw8qlQq2trYwMDDQdjlElcbc3BxXrlzBo0ePKhRuOKCYiKiGet5b0BPVNJV1BZJnBhEREUkKww0RERFJCsfcEBFJiP2kXVW6viuzu1Xp+krD3t4eY8eOxdixY8s1/9q1azF27FjcuXOnUuuSgoru26rCKzdERFRlhgwZgl69er3QdRw/fhwjRowoVV97e3tER0drtAUEBOD8+fPlXv/atWshk8kgk8kgl8thbW2NgIAAXLt2rdzLrC7Ksm+1ieGGiIgkxdzcvEJPkenr68PCwqJCNZiYmODmzZu4ceMGtm7diuTkZPTr169CyyyNR48evdDlV3TfVhWGGyIiqjZ++ukneHl5QaFQwNraGpMmTUJ+fr56+t27dzFo0CAYGhrC2toaCxYsQPv27TVukzx5NUYIgWnTpqFhw4ZQKBSoX78+xowZAwBo3749rl69inHjxqmvtACPr7zUrl1bo67vvvsOrVq1glKphJmZGXr37v3M7ZDJZLCysoK1tTVat26NYcOG4dixY8jOzlb3+fbbb/Hqq69CqVSicePGmD59usa2njt3Dm3btoVSqYSLiwv2798PmUyGHTt2AACuXLkCmUyGuLg4+Pr6QqlU4uuvvwYAfPHFF2jatCmUSiWcnZ2xbNky9XLz8vIQGhoKa2trKJVK2NnZITIy8rn76+l9CwDXrl1Dz549YWRkBBMTE/Tv3x/p6enq6dOmTYO7uzvWr18Pe3t7mJqa4p133sHdu3efuf8qimNuKllV3++uTNXx3nl1UZOPK8Bj+yw18djaGOtg2hsWyNPPhpu9UtvlVJobN26ga9euGDJkCL788kucO3cOISEhUCqVmDZtGgAgLCwMhw8fxs6dO2FpaYmpU6fixIkTcHd3L7K8P67fwb5d32J+VBTmLI1Bk1eckZmRgfNnz+CP63cwc/Ea9PNvi74Dh6DvwED1PKn/3odKCPxx/Q4A4Of4vRg7bBCGj/4QH89dgkeP8nDowD719Kc9Pf8/mbewfuNm6Ojo4K+0uzDIVuHE0SMYHTwYE6fPwadePki9ehkzJo1FevZDvDduIppZG6NXr15o2LAhjh49irt37+LDDz8sdn2TJk3C/Pnz0bJlS3XAmTp1KpYsWYKWLVvi999/R0hICAwNDREUFIRFixZh586d2LRpExo2bIjU1FSkpqYCALZu3YoFCxZg48aNaNasGdLS0nDq1Kli16tSqdTB5qeffkJ+fj5GjRqFgIAAJCQkqPulpKRgx44d+P7773H79m30798fs2fPxqxZs579DVEBDDdERFQtLFu2DLa2tliyZAlkMhmcnZ3x999/Y+LEiZg6dSpycnKwbt06bNiwAR06dAAArFmzBvXr1y9xmTdvXEc9c0t4t20PXV1dWNvYwrWlBwDAtE4d6OjowNDICGYWliUu44vF8+H/Vh+M/DBc3ebk4vrMbbmbnY3XnBpACIGHDx5/RMbAof+DgYEhAGBF9FwMHTkWb/UbAABoYGePUeMnI3rWNLw3biL27duHlJQUJCQkwMrKCgAwa9YsdOzYsci6xo4diz59+qi/joiIwPz589VtjRo1wl9//YWVK1ciKCgI165dg6OjI9q2bQuZTAY7Ozv1vNeuXYOVlRX8/Pygq6uLhg0bwsvLq9htjI+Px+nTp3H58mXY2toCAL788ks0a9YMx48fR6tWrQA8DkFr166FsbExAGDw4MGIj49nuCEiIuk7e/YsfHx8NN7IrU2bNrh37x6uX7+O27dv49GjRxq/bE1NTeHk5FTiMjt174mvY5ajWxt3tGnvh7ZvdIRvx86oVav0v/6S/zyDPgOCyrQthkbG2Lg7Afn5j3Do4H7s3rEZoyd8op5+/q8zOHn8KFYvjlK3qQoKkJv7EA8e3EdycjJsbW3VwQZAiSHD09NT/f+cnBykpKRg2LBhCAkJUbfn5+fD1NQUwONB3R07doSTkxM6d+6M7t27o1OnTgCAfv36ITo6Go0bN0bnzp3RtWtX9OjRo9j9dfbsWdja2qqDDQC4uLigdu3aOHv2rDrc2Nvbq4MNAFhbWyMjI6N0O7KcGG6IiEiyrOo3wLcJx/HroQT8+ksCPvtkPNatXISYzbugq6tbqmUolGW/9SeXy9CwUWMAQGNHJ1y/ehmfTv4Qny1cCQC4n5OD9z+chA6dexRdn6Js6zM0NFT//969ewCA1atXw9vbW6Nf4ccZvPrqq7h8+TJ++OEH7N+/H/3794efnx+2bNkCW1tbJCcnY//+/di3bx9GjhyJefPm4aeffir1/nra0/PJZDKoVKpyLau0OKCYiIiqhaZNmyIxMRFCCHXb4cOHYWxsjAYNGqBx48bQ1dXF8ePH1dOzsrKe+9i2Ul8f7Tt2waQZcxCz6TucSjqOi+f+AgDU0tVDQUHBM+d3bNoMRw//VIEtA4aOGou9323H2dOPx680dW2BKykX0bBR4yIvuVwOJycnpKamagzOfXK7S2JpaYn69evj0qVLcHBw0Hg1atRI3c/ExAQBAQFYvXo14uLisHXrVvz7778AHj8t1qNHDyxatAgJCQlITEzE6dOni6yradOmGuN1AOCvv/7CnTt34OLiUu59VRl45YaIiKpUVlYWTp48qdFWr149jBw5EtHR0Rg9ejRCQ0ORnJyMiIgIhIWFQS6Xw9jYGEFBQfjoo49Qt25dWFhYICIiAnK5vMTPJPp20wYUqArg6u4BfX0DfL9tE5RKfVg3eHwrpX6Dhjhx9Ag6v9UHegoF6tStV2QZ742biBHv9IStXSN0fqsPCvLz8cvBfRg6cmypt9mqfgO86d8dS+d/hiVr4zDigwkYE/wOrG0awK/rW5DL5Uj+6wxSks8idMIn6NixI5o0aYKgoCDMnTsXd+/exSefPL6t9bzPX5o+fTrGjBkDU1NTdO7cGbm5ufjtt99w+/ZthIWFISoqCtbW1mjZsiXkcjk2b94MKysr1K5dG2vXrkVBQQG8vb1hYGCAr776Cvr6+hrjcgr5+fnB1dUVgwYNQnR0NPLz8zFy5Ej4+vpq3CrTBoYbIiIJqQlPxiUkJKBly5YabcOGDcMXX3yB3bt346OPPoKbmxvq1q2LYcOGqX+pA0BUVBTee+89dO/eHSYmJpgwYQJSU1OhLOHWkbGJKWKXRWP+jI9RUKCCo7MLFq35BrXr1AUAjBofjpmTxqF7u1eRl5uLU6m3iyyjlU9bzFuxFqsWzkPssmgYGRnjVe/WZd7uwSHvY3DPTjj9exLatO+ARWs2YtXCuVizbCFq6daCfZNX0GfAYACPbyHt2LEDw4cPR6tWrdC4cWPMmzcPPXr0KHFbCw0fPhwGBgaYN28ePvroIxgaGsLV1VX9uLyxsTHmzp2LCxcuQEdHB61atcLu3bshl8tRu3ZtzJ49G2FhYSgoKICrqyu+++471KtXNPTJZDJ8++23GD16NF5//XXI5XJ07twZixcvLvO+qWwy8eT1v5dAdnY2TE1NkZWVBRMTk0pffk18rLRQTfihqC01+bgCPLbPUhOPbeGj4Bb1G8DNvmJvNlfT5eTkwMbGBvPnz8ewYcM0ppX0qHZN0KJB7SJthw8fRtu2bXHx4kU0adKk6ouqAg8fPsTly5fRqFGjIiGuLL+/eeWGiIhqjN9//x3nzp2Dl5cXsrKyMGPGDABAz549tVxZ5du+fTuMjIzg6OiIixcv4oMPPkCbNm0kG2wqE8MNERHVKJ9//jmSk5Ohp6cHDw8P/PLLLzAzM9N2WZXu7t27mDhxIq5duwYzMzP4+flh/vz52i6rRmC4ISKiGqNly5ZISkrSdhlVIjAwEIGBgdouo0bio+BEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpfBSciEhKpplW8fqyqnZ9T2jfvj3c3d0RHR2ttRqoetL6lZulS5fC3t4eSqUS3t7eOHbs2DP7R0dHw8nJCfr6+rC1tcW4cePw8OHDKqqWiIgqYsiQIZDJZJg9e7ZG+44dO577gZBP27ZtG2bOnFmZ5RUxZdxIuNnWUb9ed22M9999G+fPnnmh66WK0Wq4iYuLQ1hYGCIiInDixAm4ubnB398fGRkZxfbfsGEDJk2ahIiICJw9exYxMTGIi4vD5MmTq7hyIiIqL6VSiTlz5uD27aIfUlkWdevWhbGxcSVVVbI27TsgPukc4pPOYdXGb6FTSwejh7zzwtdL5afVcBMVFYWQkBAEBwfDxcUFK1asgIGBAWJjY4vtf+TIEbRp0wYDBw6Evb09OnXqhAEDBjz3ag8REVUffn5+sLKyQmRkZIl9/vnnHwwYMAA2NjYwMDCAq6srvvnmG40+7du3V3/S9eTJk+Ht7V1kOf06tcWK6Lnqr7d98yV6veGNVg5W6NneC3HrvnhuvXp6CphZWMLMwhLOzVwxdORYpP19A//+k6nus+CzCPR43RPejvXRtY07lsybhUePHgEAbqReg3vDuvjz1O8ay/3qi+Xo/JorVCoVAODCub8wcvDbeM2pASwtLTF48GBkZv63ji1btsDV1RX6+vqoV68e/Pz8kJOT89z6X0ZaCzd5eXlISkqCn5/ff8XI5fDz80NiYmKx87Ru3RpJSUnqMHPp0iXs3r0bXbt2LXE9ubm5yM7O1ngREZH26Ojo4LPPPsPixYtx/fr1Yvs8fPgQHh4e2LVrF86cOYMRI0Zg8ODBJf4xO2jQIBw7dgwpKSnqtovJZ3H+7J/o2vNtAMCu7Zuw7PNIhE74BNsPHMXoiVOw9PPPsHPzN8Uuszj3c+5h1/ZNaGjfGLXr1FW3GxoaY2bUUmw78CsmTIvEtm++xFdfLAMA2Ng2hHfb9vh209cay/p209d4q99AyOVyZGdlIeSdnnBu1gLf7DqAPXv2ID09Hf379wcA3Lx5EwMGDMDQoUNx9uxZJCQkoE+fPhBClLr2l4nWBhRnZmaioKAAlpaWGu2WlpY4d+5csfMMHDgQmZmZaNu2LYQQyM/Px3vvvffM21KRkZGYPn16pdZOREQV07t3b7i7uyMiIgIxMTFFptvY2GD8+PHqr0ePHo29e/di06ZN8PLyKtK/WbNmcHNzw4YNGzBlyhQAwO7tm+Ha0hMNGzUGACyfPxsfTpkJvy49AAANGtrh0vlkbPl6Dd7qN6DEWn+O34vXnBoAAB7cz4G5hRUWr90Iufy/6wMjPvivVhvbhriachF7dm5D8PsfAAD6DBiMT8PDMH7qLOgpFDh7+hQunPsL0TEbAAAb166Gc7MWGDNpKgCgRYPaiI2Nha2tLc6fP4979+4hPz8fffr0gZ2dHQDA1dX1ebv5paX1AcVlkZCQgM8++wzLli3DiRMnsG3bNuzateuZA8rCw8ORlZWlfqWmplZhxUREVJI5c+Zg3bp1OHv2bJFpBQUFmDlzJlxdXVG3bl0YGRlh7969uHbtWonLGzRoEDZseBwWhBD4YedWdO3dDwBw/34OUq9exrSPxuA1pwbq1+rFnyP16pVn1tmqdTts2vMzNu35GV9/Fw8f3zcxMrAf/r7+Xy17dm5DUG9/vPmqE15zaoAln8/Czb//uyr1pn836OjoIH7P9wCAbzdvQKvW7WBj2xAAcP7sGRxP/EVdl5GREZydnQEAKSkpcHNzQ4cOHeDq6op+/fph9erVFR6zJGVau3JjZmYGHR0dpKena7Snp6fDysqq2HmmTJmCwYMHY/jw4QAep9acnByMGDECH3/8sUaKLqRQKKBQKCp/A4iIqEJef/11+Pv7Izw8HEOGDNGYNm/ePCxcuBDR0dFwdXWFoaEhxo4di7y8vBKXN2DAAEycOBEnTpzAgwcPkP73Dfj36A0AePD/Y1Omzo2Gq7unxnxyHZ1n1qmvb6C++gMATV3d0MbFDts2fInQCZ/gVNIxTB4zAu+HTUJr3w4wMjHBnm+3Yf3qJep5dPX00L3vO/h20wb4demBH3ZswYTp/405up9zD75+nTE2fBoAwNnaRD3N2toaOjo62LdvH44cOYIff/wRixcvxscff4yjR4+iUaNGz6z/ZaS1cKOnpwcPDw/Ex8ejV69eAACVSoX4+HiEhoYWO8/9+/eLBBid//+m5H1HIqKaZ/bs2XB3d4eTk5NG++HDh9GzZ0+8++67AB7/fjh//jxcXFxKXFaDBg3g6+uLr7/+Gg8ePMBr7dqjnpk5AKCeuQXMLa1x/epVdOvdv0I1y2QyyOVy9duQnPztGKxtbBEy5r9bUzdvFL1L0GfAYPT1a424L2NQUJCPDp17qKc1be6G/T98h/q2DVGrVi04NKhd7HrbtGmDNm3aYOrUqbCzs8P27dsRFhZWoe2RIq2+iV9YWBiCgoLg6ekJLy8vREdHIycnB8HBwQCAwMBA2NjYqEfU9+jRA1FRUWjZsiW8vb1x8eJFTJkyBT169FCHHCIiqjlcXV0xaNAgLFq0SKPd0dERW7ZswZEjR1CnTh1ERUUhPT39meEGeHxrKiIiAnl5eRg35VONaSM/nIQ5UyfByMQEbdp3wKPcXPz5x0lkZ91B4IhRJS4zLy8XmRmP7zJkZ93BxrWrH19p6dgZAGDXqDHS/r6OH77diuZur+LnAz/iwP/ffnpSY0cntHjVE9GR09Cr/yAo9fXV0wKChmPrN19iUuhwDHlvDAxz7XDx4kVs3LgRX3zxBX777TfEx8ejU6dOsLCwwNGjR3Hr1i00bdr02Tv4JaXVcBMQEIBbt25h6tSpSEtLg7u7O/bs2aMeZHzt2jWNKzWffPIJZDIZPvnkE9y4cQPm5ubo0aMHZs2apa1NICKqXrT4jsHlNWPGDMTFxWm0ffLJJ7h06RL8/f1hYGCAESNGoFevXsjKevb2vf322wgNDYWOjg7e9O+mMa3PgEAolfpYu3IxFsyaCn19Azg6u2DQsPefuczDCfHo4PF4/IuhkTHsmzji8xVr0cqnLQCgfaeueHf4+5g9ZQLy8vLQ7s2OGPHBR1ixYHaRZfUKGIyTvx1Dr4B3NdotrKyxbvseRH82De+92wf5eXmws7ND586dIZfLYWJigp9//hnR0dHIzs6GnZ0d5s+fjy5dujyz9peVTLxk93Oys7NhamqKrKwsmJiYPH+GMrKftKvSl1lVrszu9vxOL6mafFwBHttnqYnH1sZYB9PesIBF/QZws7fQdjnV1h/X72i7hCJWRs/Dvl07sGXf4Wf2a1HMbamXwcOHD3H58mU0atQISqVSY1pZfn/XqKeliIiIaqL7Ofdw4dxf2LhuNQYEj9B2OZLHcENERPSCRX4yAQO6vQHP19oWuSVFlY+fCk5ERPSCzVywDDMXLNN2GS8NXrkhIiIiSWG4ISKqYVQCAATwcj0PQi+BynrGieGGiKiGufNQhUcFAiK/5HfrJaqJCt+BuqLvXccxN0RENcyDfIH4S/fQXU8H//xjAAMDA8hkMm2XVe3U5PBX+O7HLxOVSoVbt27BwMAAtWpVLJ4w3BAR1UDbzj7+rCQrkwwtV1J9Zdx+oO0Syk3vgf7zO0mQXC5Hw4YNKxzWGW6IiGogAWDr2RzMffcVPHr0SNvlVEvDtyVou4Ryi/+wvbZL0Ao9Pb1iPwS7rBhuiIhqMB0dHX62Xglu3C3Qdgnl9vS781LZcEAxERERSQrDDREREUkKww0RERFJCsMNERERSQrDDREREUkKww0RERFJCsMNERERSQrDDREREUkKww0RERFJCsMNERERSQrDDREREUkKww0RERFJCsMNERERSQrDDREREUkKww0RERFJCsMNERERSQrDDREREUkKww0RERFJCsMNERERSQrDDREREUlKtQg3S5cuhb29PZRKJby9vXHs2LES+7Zv3x4ymazIq1u3blVYMREREVVXWg83cXFxCAsLQ0REBE6cOAE3Nzf4+/sjIyOj2P7btm3DzZs31a8zZ85AR0cH/fr1q+LKiYiIqDrSeriJiopCSEgIgoOD4eLighUrVsDAwACxsbHF9q9bty6srKzUr3379sHAwIDhhoiIiABoOdzk5eUhKSkJfn5+6ja5XA4/Pz8kJiaWahkxMTF45513YGhoWOz03NxcZGdna7yIiIhIurQabjIzM1FQUABLS0uNdktLS6SlpT13/mPHjuHMmTMYPnx4iX0iIyNhamqqftna2la4biIiIqq+tH5bqiJiYmLg6uoKLy+vEvuEh4cjKytL/UpNTa3CComIiKiq1dLmys3MzKCjo4P09HSN9vT0dFhZWT1z3pycHGzcuBEzZsx4Zj+FQgGFQlHhWomIiKhm0OqVGz09PXh4eCA+Pl7dplKpEB8fDx8fn2fOu3nzZuTm5uLdd9990WUSERFRDaLVKzcAEBYWhqCgIHh6esLLywvR0dHIyclBcHAwACAwMBA2NjaIjIzUmC8mJga9evVCvXr1tFE2ERERVVNaDzcBAQG4desWpk6dirS0NLi7u2PPnj3qQcbXrl2DXK55gSk5ORmHDh3Cjz/+qI2SiYiIqBrTergBgNDQUISGhhY7LSEhoUibk5MThBAvuCoiIiKqiWr001JERERET2O4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSdF6uFm6dCns7e2hVCrh7e2NY8eOPbP/nTt3MGrUKFhbW0OhUOCVV17B7t27q6haIiIiqu5qaXPlcXFxCAsLw4oVK+Dt7Y3o6Gj4+/sjOTkZFhYWRfrn5eWhY8eOsLCwwJYtW2BjY4OrV6+idu3aVV88ERERVUtaDTdRUVEICQlBcHAwAGDFihXYtWsXYmNjMWnSpCL9Y2Nj8e+//+LIkSPQ1dUFANjb2z9zHbm5ucjNzVV/nZ2dXXkbQERERNWO1m5L5eXlISkpCX5+fv8VI5fDz88PiYmJxc6zc+dO+Pj4YNSoUbC0tETz5s3x2WefoaCgoMT1REZGwtTUVP2ytbWt9G0hIiKi6kNr4SYzMxMFBQWwtLTUaLe0tERaWlqx81y6dAlbtmxBQUEBdu/ejSlTpmD+/Pn49NNPS1xPeHg4srKy1K/U1NRK3Q4iIiKqXrR6W6qsVCoVLCwssGrVKujo6MDDwwM3btzAvHnzEBERUew8CoUCCoWiiislIiIibdFauDEzM4OOjg7S09M12tPT02FlZVXsPNbW1tDV1YWOjo66rWnTpkhLS0NeXh709PReaM1ERERU/WnttpSenh48PDwQHx+vblOpVIiPj4ePj0+x87Rp0wYXL16ESqVSt50/fx7W1tYMNkRERARAy+9zExYWhtWrV2PdunU4e/Ys3n//feTk5KifngoMDER4eLi6//vvv49///0XH3zwAc6fP49du3bhs88+w6hRo7S1CURERFTNaHXMTUBAAG7duoWpU6ciLS0N7u7u2LNnj3qQ8bVr1yCX/5e/bG1tsXfvXowbNw4tWrSAjY0NPvjgA0ycOFFbm0BERETVjNYHFIeGhiI0NLTYaQkJCUXafHx88Ouvv77gqoiIiKim0vrHLxARERFVJoYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpKUahFuli5dCnt7eyiVSnh7e+PYsWMl9l27di1kMpnGS6lUVmG1REREVJ1pPdzExcUhLCwMEREROHHiBNzc3ODv74+MjIwS5zExMcHNmzfVr6tXr1ZhxURERFSdaT3cREVFISQkBMHBwXBxccGKFStgYGCA2NjYEueRyWSwsrJSvywtLauwYiIiIqrOtBpu8vLykJSUBD8/P3WbXC6Hn58fEhMTS5zv3r17sLOzg62tLXr27Ik///yzxL65ubnIzs7WeBEREZF0aTXcZGZmoqCgoMiVF0tLS6SlpRU7j5OTE2JjY/Htt9/iq6++gkqlQuvWrXH9+vVi+0dGRsLU1FT9srW1rfTtICIioupD67elysrHxweBgYFwd3eHr68vtm3bBnNzc6xcubLY/uHh4cjKylK/UlNTq7hiIiIiqkq1tLlyMzMz6OjoID09XaM9PT0dVlZWpVqGrq4uWrZsiYsXLxY7XaFQQKFQVLhWIiIiqhm0euVGT08PHh4eiI+PV7epVCrEx8fDx8enVMsoKCjA6dOnYW1t/aLKJCIiohpEq1duACAsLAxBQUHw9PSEl5cXoqOjkZOTg+DgYABAYGAgbGxsEBkZCQCYMWMGXnvtNTg4OODOnTuYN28erl69iuHDh2tzM4iIiKiaqFC4ycvLw+XLl9GkSRPUqlW+RQUEBODWrVuYOnUq0tLS4O7ujj179qgHGV+7dg1y+X8XmG7fvo2QkBCkpaWhTp068PDwwJEjR+Di4lKRTSEiIiKJKFciuX//PkaPHo1169YBAM6fP4/GjRtj9OjRsLGxwaRJk8q0vNDQUISGhhY7LSEhQePrBQsWYMGCBeUpm4iIiF4C5RpzEx4ejlOnTiEhIUHjow/8/PwQFxdXacURERERlVW5rtzs2LEDcXFxeO211yCTydTtzZo1Q0pKSqUVR0RERFRW5bpyc+vWLVhYWBRpz8nJ0Qg7RERERFWtXOHG09MTu3btUn9dGGi++OKLUj/CTURERPQilOu21GeffYYuXbrgr7/+Qn5+PhYuXIi//voLR44cwU8//VTZNRIRERGVWrmu3LRt2xanTp1Cfn4+XF1d8eOPP8LCwgKJiYnw8PCo7BqJiIiISq3MV24ePXqE//3vf5gyZQpWr179ImoiIiIiKrcyX7nR1dXF1q1bX0QtRERERBVWrttSvXr1wo4dOyq5FCIiIqKKK9eAYkdHR8yYMQOHDx+Gh4cHDA0NNaaPGTOmUoojIiIiKqtyhZuYmBjUrl0bSUlJSEpK0pgmk8kYboiIiEhryhVuLl++XNl1EBEREVWKco25eZIQAkKIyqiFiIiIqMLKHW6+/PJLuLq6Ql9fH/r6+mjRogXWr19fmbURERERlVm5bktFRUVhypQpCA0NRZs2bQAAhw4dwnvvvYfMzEyMGzeuUoskIiIiKq1yhZvFixdj+fLlCAwMVLe99dZbaNasGaZNm8ZwQ0RERFpTrttSN2/eROvWrYu0t27dGjdv3qxwUURERETlVa5w4+DggE2bNhVpj4uLg6OjY4WLIiIiIiqvct2Wmj59OgICAvDzzz+rx9wcPnwY8fHxxYYeIiIioqpSris3ffv2xdGjR2FmZoYdO3Zgx44dMDMzw7Fjx9C7d+/KrpGIiIio1Mp15QYAPDw88NVXX1VmLUREREQVVq4rN7t378bevXuLtO/duxc//PBDhYsiIiIiKq9yhZtJkyahoKCgSLsQApMmTapwUURERETlVa5wc+HCBbi4uBRpd3Z2xsWLFytcFBEREVF5lSvcmJqa4tKlS0XaL168CENDwwoXRURERFRe5Qo3PXv2xNixY5GSkqJuu3jxIj788EO89dZblVYcERERUVmVK9zMnTsXhoaGcHZ2RqNGjdCoUSM4OzujXr16+Pzzzyu7RiIiIqJSK9ej4Kampjhy5Aj27duHU6dOQV9fH25ubmjXrl1l10dERERUJmW6cpOYmIjvv/8eACCTydCpUydYWFjg888/R9++fTFixAjk5ua+kEKJiIiISqNM4WbGjBn4888/1V+fPn0aISEh6NixIyZNmoTvvvsOkZGRlV4kERERUWmVKdycPHkSHTp0UH+9ceNGeHl5YfXq1QgLC8OiRYvK9dlSS5cuhb29PZRKJby9vXHs2LFSzbdx40bIZDL06tWrzOskIiIiaSpTuLl9+zYsLS3VX//000/o0qWL+utWrVohNTW1TAXExcUhLCwMEREROHHiBNzc3ODv74+MjIxnznflyhWMHz+e43yIiIhIQ5nCjaWlJS5fvgwAyMvLw4kTJ/Daa6+pp9+9exe6urplKiAqKgohISEIDg6Gi4sLVqxYAQMDA8TGxpY4T0FBAQYNGoTp06ejcePGZVofERERSVuZwk3Xrl0xadIk/PLLLwgPD4eBgYHGlZM//vgDTZo0KfXy8vLykJSUBD8/v/8Kksvh5+eHxMTEEuebMWMGLCwsMGzYsOeuIzc3F9nZ2RovIiIikq4yPQo+c+ZM9OnTB76+vjAyMsK6deugp6ennh4bG4tOnTqVenmZmZkoKCjQuNUFPL5CdO7cuWLnOXToEGJiYnDy5MlSrSMyMhLTp08vdU1ERERUs5Up3JiZmeHnn39GVlYWjIyMoKOjozF98+bNMDIyqtQCn3T37l0MHjwYq1evhpmZWanmCQ8PR1hYmPrr7Oxs2NravqgSiYiISMvK/SZ+xalbt26ZlmNmZgYdHR2kp6drtKenp8PKyqpI/5SUFFy5cgU9evRQt6lUKgBArVq1kJycXOS2mEKhgEKhKFNdREREVHOV6+MXKouenh48PDwQHx+vblOpVIiPj4ePj0+R/s7Ozjh9+jROnjypfr311lt44403cPLkSV6RISIiovJdualMYWFhCAoKgqenJ7y8vBAdHY2cnBwEBwcDAAIDA2FjY4PIyEgolUo0b95cY/7atWsDQJF2IiIiejlpPdwEBATg1q1bmDp1KtLS0uDu7o49e/aoBxlfu3YNcrlWLzARERFRDaL1cAMAoaGhCA0NLXZaQkLCM+ddu3Zt5RdERERENRYviRAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaRUi3CzdOlS2NvbQ6lUwtvbG8eOHSux77Zt2+Dp6YnatWvD0NAQ7u7uWL9+fRVWS0RERNWZ1sNNXFwcwsLCEBERgRMnTsDNzQ3+/v7IyMgotn/dunXx8ccfIzExEX/88QeCg4MRHByMvXv3VnHlREREVB1pPdxERUUhJCQEwcHBcHFxwYoVK2BgYIDY2Nhi+7dv3x69e/dG06ZN0aRJE3zwwQdo0aIFDh06VMWVExERUXWk1XCTl5eHpKQk+Pn5qdvkcjn8/PyQmJj43PmFEIiPj0dycjJef/31Yvvk5uYiOztb40VERETSpdVwk5mZiYKCAlhaWmq0W1paIi0trcT5srKyYGRkBD09PXTr1g2LFy9Gx44di+0bGRkJU1NT9cvW1rZSt4GIiIiqF63flioPY2NjnDx5EsePH8esWbMQFhaGhISEYvuGh4cjKytL/UpNTa3aYomIiKhK1dLmys3MzKCjo4P09HSN9vT0dFhZWZU4n1wuh4ODAwDA3d0dZ8+eRWRkJNq3b1+kr0KhgEKhqNS6iYiIqPrS6pUbPT09eHh4ID4+Xt2mUqkQHx8PHx+fUi9HpVIhNzf3RZRIRERENYxWr9wAQFhYGIKCguDp6QkvLy9ER0cjJycHwcHBAIDAwEDY2NggMjISwOMxNJ6enmjSpAlyc3Oxe/durF+/HsuXL9fmZhAREVE1ofVwExAQgFu3bmHq1KlIS0uDu7s79uzZox5kfO3aNcjl/11gysnJwciRI3H9+nXo6+vD2dkZX331FQICArS1CURERFSNaD3cAEBoaChCQ0OLnfb0QOFPP/0Un376aRVURURERDVRjXxaioiIiKgkDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQp1SLcLF26FPb29lAqlfD29saxY8dK7Lt69Wq0a9cOderUQZ06deDn5/fM/kRERPRy0Xq4iYuLQ1hYGCIiInDixAm4ubnB398fGRkZxfZPSEjAgAEDcPDgQSQmJsLW1hadOnXCjRs3qrhyIiIiqo60Hm6ioqIQEhKC4OBguLi4YMWKFTAwMEBsbGyx/b/++muMHDkS7u7ucHZ2xhdffAGVSoX4+PgqrpyIiIiqI62Gm7y8PCQlJcHPz0/dJpfL4efnh8TExFIt4/79+3j06BHq1q1b7PTc3FxkZ2drvIiIiEi6tBpuMjMzUVBQAEtLS412S0tLpKWllWoZEydORP369TUC0pMiIyNhamqqftna2la4biIiIqq+tH5bqiJmz56NjRs3Yvv27VAqlcX2CQ8PR1ZWlvqVmppaxVUSERFRVaqlzZWbmZlBR0cH6enpGu3p6emwsrJ65ryff/45Zs+ejf3796NFixYl9lMoFFAoFJVSLxEREVV/Wr1yo6enBw8PD43BwIWDg318fEqcb+7cuZg5cyb27NkDT0/PqiiViIiIagitXrkBgLCwMAQFBcHT0xNeXl6Ijo5GTk4OgoODAQCBgYGwsbFBZGQkAGDOnDmYOnUqNmzYAHt7e/XYHCMjIxgZGWltO4iIiKh60Hq4CQgIwK1btzB16lSkpaXB3d0de/bsUQ8yvnbtGuTy/y4wLV++HHl5eXj77bc1lhMREYFp06ZVZelERERUDWk93ABAaGgoQkNDi52WkJCg8fWVK1defEFERERUY9Xop6WIiIiInsZwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSovVws3TpUtjb20OpVMLb2xvHjh0rse+ff/6Jvn37wt7eHjKZDNHR0VVXKBEREdUIWg03cXFxCAsLQ0REBE6cOAE3Nzf4+/sjIyOj2P73799H48aNMXv2bFhZWVVxtURERFQTaDXcREVFISQkBMHBwXBxccGKFStgYGCA2NjYYvu3atUK8+bNwzvvvAOFQlHF1RIREVFNoLVwk5eXh6SkJPj5+f1XjFwOPz8/JCYmVtp6cnNzkZ2drfEiIiIi6dJauMnMzERBQQEsLS012i0tLZGWllZp64mMjISpqan6ZWtrW2nLJiIioupH6wOKX7Tw8HBkZWWpX6mpqdouiYiIiF6gWtpasZmZGXR0dJCenq7Rnp6eXqmDhRUKBcfnEBERvUS0duVGT08PHh4eiI+PV7epVCrEx8fDx8dHW2URERFRDae1KzcAEBYWhqCgIHh6esLLywvR0dHIyclBcHAwACAwMBA2NjaIjIwE8HgQ8l9//aX+/40bN3Dy5EkYGRnBwcFBa9tBRERE1YdWw01AQABu3bqFqVOnIi0tDe7u7tizZ496kPG1a9cgl/93cenvv/9Gy5Yt1V9//vnn+Pzzz+Hr64uEhISqLp+IiIiqIa2GGwAIDQ1FaGhosdOeDiz29vYQQlRBVURERFRTSf5pKSIiInq5MNwQERGRpGj9thRVI9NMtV1BxUzL0nYFRFWvJp+3PGfpBWG4IXoZ8BcgUc1Sk89ZQOvnLW9LERERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkVItws3TpUtjb20OpVMLb2xvHjh17Zv/NmzfD2dkZSqUSrq6u2L17dxVVSkRERNWd1sNNXFwcwsLCEBERgRMnTsDNzQ3+/v7IyMgotv+RI0cwYMAADBs2DL///jt69eqFXr164cyZM1VcOREREVVHWg83UVFRCAkJQXBwMFxcXLBixQoYGBggNja22P4LFy5E586d8dFHH6Fp06aYOXMmXn31VSxZsqSKKyciIqLqqJY2V56Xl4ekpCSEh4er2+RyOfz8/JCYmFjsPImJiQgLC9No8/f3x44dO4rtn5ubi9zcXPXXWVlZAIDs7OwKVl88Ve79F7LcqpAtE9ouoWJe0DEFavZxBWr4sX2BxxXgsdUqHtsS1ejjCryQY1v4e1uI5+8brYabzMxMFBQUwNLSUqPd0tIS586dK3aetLS0YvunpaUV2z8yMhLTp08v0m5ra1vOqqXLVNsFVNTsGr8FL0yN3jM8rs9Uo/cOj22JavyeeYHH9u7duzA1ffbytRpuqkJ4eLjGlR6VSoV///0X9erVg0wm02Jl1Ut2djZsbW2RmpoKExMTbZdDlYjHVrp4bKWJx7V4QgjcvXsX9evXf25frYYbMzMz6OjoID09XaM9PT0dVlZWxc5jZWVVpv4KhQIKhUKjrXbt2uUvWuJMTEx4MkkUj6108dhKE49rUc+7YlNIqwOK9fT04OHhgfj4eHWbSqVCfHw8fHx8ip3Hx8dHoz8A7Nu3r8T+RERE9HLR+m2psLAwBAUFwdPTE15eXoiOjkZOTg6Cg4MBAIGBgbCxsUFkZCQA4IMPPoCvry/mz5+Pbt26YePGjfjtt9+watUqbW4GERERVRNaDzcBAQG4desWpk6dirS0NLi7u2PPnj3qQcPXrl2DXP7fBabWrVtjw4YN+OSTTzB58mQ4Ojpix44daN68ubY2QRIUCgUiIiKK3MKjmo/HVrp4bKWJx7XiZKI0z1QRERER1RBafxM/IiIiosrEcENERESSwnBDREREksJwQ0RERJLCcEMkcTKZrMTPXqtIX6q5njzOV65cgUwmw8mTJ7VaE1FlYripxhITE6Gjo4Nu3bppuxSqJEOGDIFMJoNMJoOenh4cHBwwY8YM5Ofnv7B13rx5E126dKn0vlQ+T34P6OrqolGjRpgwYQIePnyo7dKoBE8esydfFy9eBAD8/PPP6NGjB+rXr1/qPxAKCgowe/ZsODs7Q19fH3Xr1oW3tze++OKLF7w1Lwetv88NlSwmJgajR49GTEwM/v7771J9nsaLkJeXBz09Pa2sW4o6d+6MNWvWIDc3F7t378aoUaOgq6uL8PBwjX6Vtd9L+miSival8iv8Hnj06BGSkpIQFBQEmUyGOXPmaLs0KkHhMXuSubk5ACAnJwdubm4YOnQo+vTpU6rlTZ8+HStXrsSSJUvg6emJ7Oxs/Pbbb7h9+3al117oZfpZzis31dS9e/cQFxeH999/H926dcPatWs1pn/33Xdo1aoVlEolzMzM0Lt3b/W03NxcTJw4Eba2tlAoFHBwcEBMTAwAYO3atUU+W2vHjh0aHyI6bdo0uLu744svvkCjRo2gVCoBAHv27EHbtm1Ru3Zt1KtXD927d0dKSorGsq5fv44BAwagbt26MDQ0hKenJ44ePYorV65ALpfjt99+0+gfHR0NOzs7qFSqiu6yGkOhUMDKygp2dnZ4//334efnh507d2LIkCHo1asXZs2ahfr168PJyQkAkJqaiv79+6N27dqoW7cuevbsiStXrmgsMzY2Fs2aNYNCoYC1tTVCQ0PV0578SzIvLw+hoaGwtraGUqmEnZ2d+t2/n+4LAKdPn8abb74JfX191KtXDyNGjMC9e/fU0wtr/vzzz2FtbY169eph1KhRePToUeXvOAkp/B6wtbVFr1694Ofnh3379gF4/BE0kZGRaNSoEfT19eHm5oYtW7ZozP/nn3+ie/fuMDExgbGxMdq1a6c+F48fP46OHTvCzMwMpqam8PX1xYkTJ6p8G6Wm8Jg9+dLR0QEAdOnSBZ9++qnGz+Hn2blzJ0aOHIl+/fqhUaNGcHNzw7BhwzB+/Hh1H5VKhblz58LBwQEKhQINGzbErFmz1NNLe36W52dKTcdwU01t2rQJzs7OcHJywrvvvovY2FgUvt/irl270Lt3b3Tt2hW///474uPj4eXlpZ43MDAQ33zzDRYtWoSzZ89i5cqVMDIyKtP6L168iK1bt2Lbtm3qe/E5OTkICwvDb7/9hvj4eMjlcvTu3VsdTO7duwdfX1/cuHEDO3fuxKlTpzBhwgSoVCrY29vDz8+vyF8+a9aswZAhQzTehfplo6+vj7y8PABAfHw8kpOTsW/fPnz//fd49OgR/P39YWxsjF9++QWHDx+GkZEROnfurJ5n+fLlGDVqFEaMGIHTp09j586dcHBwKHZdixYtws6dO7Fp0yYkJyfj66+/hr29fbF9c3Jy4O/vjzp16uD48ePYvHkz9u/frxGcAODgwYNISUnBwYMHsW7dOqxdu7ZIGKeSnTlzBkeOHFH/RR0ZGYkvv/wSK1aswJ9//olx48bh3XffxU8//QQAuHHjBl5//XUoFAocOHAASUlJGDp0qPrW5t27dxEUFIRDhw7h119/haOjI7p27Yq7d+9qbRupKCsrKxw4cAC3bt0qsU94eDhmz56NKVOm4K+//sKGDRvU795f2vOzPD9TJEFQtdS6dWsRHR0thBDi0aNHwszMTBw8eFAIIYSPj48YNGhQsfMlJycLAGLfvn3FTl+zZo0wNTXVaNu+fbt48lshIiJC6OrqioyMjGfWeOvWLQFAnD59WgghxMqVK4WxsbH4559/iu0fFxcn6tSpIx4+fCiEECIpKUnIZDJx+fLlZ65HSoKCgkTPnj2FEEKoVCqxb98+oVAoxPjx40VQUJCwtLQUubm56v7r168XTk5OQqVSqdtyc3OFvr6+2Lt3rxBCiPr164uPP/64xHUCENu3bxdCCDF69Gjx5ptvaiyvpL6rVq0SderUEffu3VNP37Vrl5DL5SItLU29PXZ2diI/P1/dp1+/fiIgIKD0O+UlExQUJHR0dIShoaFQKBQCgJDL5WLLli3i4cOHwsDAQBw5ckRjnmHDhokBAwYIIYQIDw8XjRo1Enl5eaVaX0FBgTA2Nhbfffeduu3J43z58mUBQPz++++Vsn1S9OQxK3y9/fbbxfZ9ct8+y59//imaNm0q5HK5cHV1Ff/73//E7t271dOzs7OFQqEQq1evLnb+0p6f5fmZIgUv75/L1VhycjKOHTuGAQMGAABq1aqFgIAA9a2lkydPokOHDsXOe/LkSejo6MDX17dCNdjZ2anvJxe6cOECBgwYgMaNG8PExET9F/+1a9fU627ZsiXq1q1b7DJ79eoFHR0dbN++HcDjW2RvvPFGiVcOpOr777+HkZERlEolunTpgoCAAEybNg0A4OrqqnFP/NSpU7h48SKMjY1hZGQEIyMj1K1bFw8fPkRKSgoyMjLw999/l/j98LQhQ4bg5MmTcHJywpgxY/Djjz+W2Pfs2bNwc3ODoaGhuq1NmzZQqVRITk5WtzVr1kx9eR4ArK2tkZGRUdrd8VJ64403cPLkSRw9ehRBQUEIDg5G3759cfHiRdy/fx8dO3ZUH28jIyN8+eWX6ttOJ0+eRLt27aCrq1vsstPT0xESEgJHR0eYmprCxMQE9+7dU5+nVD6Fx6zwtWjRogotz8XFBWfOnMGvv/6KoUOHIiMjAz169MDw4cMBPD7/cnNzSzy3S3t+lvVnilRwQHE1FBMTg/z8fI0BxEIIKBQKLFmyBPr6+iXO+6xpACCXy9W3twoVNz7iyROmUI8ePWBnZ4fVq1ejfv36UKlUaN68ufpS5vPWraenh8DAQKxZswZ9+vTBhg0bsHDhwmfOI0VvvPEGli9fDj09PdSvXx+1av13Gj693+/duwcPDw98/fXXRZZjbm5e5tt5r776Ki5fvowffvgB+/fvR//+/eHn51dkTEdZPP1LViaTvVRjqMrD0NBQfeswNjYWbm5uiImJUX8A8K5du2BjY6MxT+GHKD7vPAsKCsI///yDhQsXws7ODgqFAj4+PtK65aAFTx6zyiKXy9GqVSu0atUKY8eOxVdffYXBgwfj448/fu5xLq2y/kyRCl65qWby8/Px5ZdfYv78+Rp/JZw6dQr169fHN998gxYtWiA+Pr7Y+V1dXaFSqdT3559mbm6Ou3fvIicnR91Wmve3+Oeff5CcnIxPPvkEHTp0QNOmTYuM6m/RogVOnjyJf//9t8TlDB8+HPv378eyZcuQn59f6icLpKTwh2TDhg01gk1xXn31VVy4cAEWFhZwcHDQeJmamsLY2Bj29vYlfj8Ux8TEBAEBAVi9ejXi4uKwdevWYo9Z06ZNcerUKY3vlcOHD0Mul6sHJlLFyeVyTJ48GZ988glcXFygUChw7dq1Isfb1tYWwOPz7Jdffilx0Pbhw4cxZswYdO3aVT3IPDMzsyo3icrJxcUFwOPxNI6OjtDX1y/x3C7v+fm8nylSwXBTzXz//fe4ffs2hg0bhubNm2u8+vbti5iYGEREROCbb75BREQEzp49i9OnT6sfIbW3t0dQUBCGDh2KHTt24PLly0hISMCmTZsAAN7e3jAwMMDkyZORkpKCDRs2lGrwZ506dVCvXj2sWrUKFy9exIEDBxAWFqbRZ8CAAbCyskKvXr1w+PBhXLp0CVu3bkViYqK6T9OmTfHaa69h4sSJGDBgQKX9dSJVgwYNgpmZGXr27IlffvlFfTzHjBmD69evA3j8dNv8+fOxaNEiXLhwASdOnMDixYuLXV5UVBS++eYbnDt3DufPn8fmzZthZWVV5Am6wnUrlUoEBQXhzJkzOHjwIEaPHo3BgwerBzVS5ejXrx90dHSwcuVKjB8/HuPGjcO6deuQkpKiPp7r1q0DAISGhiI7OxvvvPMOfvvtN1y4cAHr169X34pwdHTE+vXrcfbsWRw9ehSDBg3iefaC3bt3T/2HKABcvnwZJ0+efOatwLfffhsLFizA0aNHcfXqVSQkJGDUqFF45ZVX4OzsDKVSiYkTJ2LChAnq25K//vqrenhCec/P0vxMkQRtD/ohTd27dxddu3YtdtrRo0cFAHHq1CmxdetW4e7uLvT09ISZmZno06ePut+DBw/EuHHjhLW1tdDT0xMODg4iNjZWPX379u3CwcFB6Ovri+7du4tVq1YVGVDs5uZWZP379u0TTZs2FQqFQrRo0UIkJCQUGTx35coV0bdvX2FiYiIMDAyEp6enOHr0qMZyYmJiBABx7Nixcu6lmuvJAcWlnXbz5k0RGBgozMzMhEKhEI0bNxYhISEiKytL3WfFihXCyclJ6OrqCmtrazF69Gj1NDw1SNjd3V0YGhoKExMT0aFDB3HixIli+wohxB9//CHeeOMNoVQqRd26dUVISIi4e/fuM2v+4IMPhK+vb6n3ycumpOMcGRkpzM3Nxb1790R0dLT6eJqbmwt/f3/x008/qfueOnVKdOrUSRgYGAhjY2PRrl07kZKSIoQQ4sSJE8LT01MolUrh6OgoNm/eLOzs7MSCBQvU84MDisvkWeetEEIcPHhQACjyCgoKKnGeVatWiTfeeEOYm5sLPT090bBhQzFkyBBx5coVdZ+CggLx6aefCjs7O6GrqysaNmwoPvvsM/X08pyfQpTuZ0pNJxPiqQEYRC/YzJkzsXnzZvzxxx/aLoWIiCSIt6Woyty7dw9nzpzBkiVLMHr0aG2XQ0REEsVwQ1UmNDQUHh4eaN++PYYOHartcoiISKJ4W4qIiIgkhVduiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhS/g/ICNVPjmJkJQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "lr_scores = [lr_accuracy, lr_precision, lr_recall, lr_f1]\n",
        "nb_scores = [nb_accuracy, nb_precision, nb_recall, nb_f1]\n",
        "\n",
        "x = range(len(metrics))\n",
        "\n",
        "plt.bar([i - 0.2 for i in x], lr_scores, width=0.4, label='Logistic Regression')\n",
        "plt.bar([i + 0.2 for i in x], nb_scores, width=0.4, label='Naive Bayes')\n",
        "\n",
        "# Display confusion matrices\n",
        "def display_confusion_matrix(predictions, model_name):\n",
        "    confusion_matrix = predictions.groupBy(\"label\", \"prediction\").count().orderBy(\"label\", \"prediction\")\n",
        "    print(f\"\\nConfusion Matrix for {model_name}:\")\n",
        "    confusion_matrix.show()\n",
        "\n",
        "# Display confusion matrices for both models\n",
        "display_confusion_matrix(lr_predictions, \"Logistic Regression\")\n",
        "display_confusion_matrix(nb_predictions, \"Naive Bayes\")\n",
        "# Plot Model Comparision\n",
        "plt.xticks(x, metrics)\n",
        "plt.ylabel('Score')\n",
        "plt.title('Comparison of Model Performance')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8e2169b",
      "metadata": {
        "id": "e8e2169b"
      },
      "source": [
        "Comparative Analysis\n",
        "\n",
        "In comparing the two models, the Logistic Regression obviously excels well over the Naive Bayes under all the evaluation indices. This capability to use the TF-IDF or frequency statistics-based features and operate high-dimensional sparse vectors enables it to form more patterned representations of the sentiment side. Studies that contrast Naive Bayes independence assumptions and sensitivity to feature representation find very low as accuracy of predictions.\n",
        "In the same sentiment analysis task, Logistic Regression is advised especially in CountVectorizer or TF-IDF features since it offers answer results on a probabilistic manner and balanced classification besides scale-ability in distributed environment such as PySpark. Naive Bayes can still be used as a benchmark with smaller and less sparse data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d88bb7a2",
      "metadata": {
        "id": "d88bb7a2"
      },
      "source": [
        "# Discussion\n",
        "Insights from Logistic Regression\n",
        "\n",
        "The Logistic Regression model was performing well in the Amazon Reviews with an accuracy of 0.8519, precision of 0.8520, recall of 0.8519, and an F1 score of 0.8519. The presentation of confusion suggests that the classification is balanced between negative and positive reviews with 39, 692 true negative and 41, 886 true positive. CountVectorizer produced high-dimensional sparse feature vectors, which the model was able to handle well, affirming that it is usable with TF-IDF-like representations. In addition to that, the framework pySpark allowed efficient use of distributed processing to train on large text data, showing the scalability benefits of this option. Error analysis shows that there was a general balance between false positives and false negatives and this was largely because of mixed sentiments, as well as context dependent expressions in reviews (Editorial Team, 2021).\n",
        "\n",
        "Insights from Naive Bayes\n",
        "\n",
        "Naive Bayes showed a poor score, having an accuracy of 0.0776, precision of 0.0753, recall of 0.0776 with F1 score of 0.0765. The confusion matrix reveals a tendency of one label which is a rather big bias and most of the reviews are predicted incorrectly. This result substantiates the idea that the algorithm is sensitive to feature sparseness and TF-IDF values which is against the assumptions that bear the independence expectations of Naive Bayes. The findings also note the effectiveness of proper consideration of features and preprocessing techniques to fit the probabilistic classifiers on high dimensional text data (Dataquest, 2024).\n",
        "\n",
        "Practical Recommendations\n",
        "\n",
        "In the case of large-scale sentiment analysis with TF-IDF features, Logistic Regression will be suggested because it is both stable and has scalable performance. Naive Bayes might need some other feature transformation, e.g. raw word counts, and parameter tuning in order to deliver reliable performance. The findings inform how machine learning models can be efficiently deployed on large text based datasets and they must be able to make accurate predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "211bbd6b",
      "metadata": {
        "id": "211bbd6b"
      },
      "source": [
        "# LSEP Considerations\n",
        "\n",
        "Mohan Sharma\n",
        "\n",
        "Scalability of the PySpark pipeline was reviewed. Mohan examined the preprocessing, feature extraction, and model training processes to make sure that they are able to deal with millions of Amazon reviews in an efficient way. He proposed methods of allocating work to nodes of a cluster, optimizing Spark tasks and sustaining speed as the job grows. His work also made sure that the project was able to process big data with reliability through the use of distributed computing\n",
        "\n",
        "Utkarsh Rimal\n",
        "\n",
        "Did optimization on the memory allocation and caching in the pipeline. Utkarsh introduced caching of intermediate DataFrames to eliminate the need to recalculate, assumed possible memory bottlenecks of large-dimensional feature vectors, and suggested options of resource distribution. His work enhanced runtime of systems and also made it possible to process large datasets without misusing memory.\n",
        "\n",
        "Dipak Acharya\n",
        "\n",
        "Manipulated parallel computation and optimizing performance. Dipak used logistic regression and naive bayes training in the framework of PySpark to test timing, optimize vectorization in this process, and also proposed methods to enhance the throughput. His work shortened training time of model and increased efficiency of model on large data.\n",
        "\n",
        "Hemlal Dulal\n",
        "\n",
        "Tracked pipeline performance and ensured attainment of scaled improvement. Hemal has experimented with the use of caching and parallelization techniques, has determined the end to end execution time, and has monitored the conversion of optimization into reality. His advances offered practical insights into the maintenance of big-data-processing performance and reliability."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57ed5f79",
      "metadata": {
        "id": "57ed5f79"
      },
      "source": [
        "# Reference\n",
        "\n",
        "Apache (2025a) ‘CountVectorizer’. Available at: https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.CountVectorizer.html.\n",
        "Apache (2025b) ‘Feature Extraction and Transformation - RDD-based API’. Available at: https://spark.apache.org/docs/latest/mllib-feature-extraction.html.\n",
        "Apache (2025c) ‘Machine Learning Library (MLlib) Guide’. Available at: https://spark.apache.org/docs/latest/ml-guide.html.\n",
        "Apache (2025d) ‘StopWordsRemover’. Available at: https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.StopWordsRemover.html.\n",
        "Apache (2025e) ‘Tokenizer’. Available at: https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.Tokenizer.html.\n",
        "Awan, A.A. and Navlani, A. (2023) ‘Naive Bayes Classification Tutorial using Scikit-learn’. Available at: https://www.datacamp.com/tutorial/naive-bayes-scikit-learn.\n",
        "Ayan, D. (2024) ‘Evaluating Binary Classification Models with PySpark’. Available at: https://medium.com/@demrahayan/evaluating-binary-classification-models-with-pyspark-2afc5ac7937f.\n",
        "Dataquest (2024) ‘Sentiment Analysis with Naive Bayes’. Available at: https://www.dataquest.io/blog/naive-bayes-tutorial/.\n",
        "Editorial Team (2021) ‘Sentiment Analysis with Logistic Regression’. Available at: https://towardsai.net/p/nlp/sentiment-analysis-with-logistic-regression.\n",
        "Govindaraj, P. (2024) ‘Implementing TF-IDF with Spark and Amazon EMR’. Available at: https://medium.com/@govindarajpriyanthan/implementing-tf-idf-with-spark-and-amazon-emr-93d0f776b646.\n",
        "Kim, R. (2018) ‘Sentiment Analysis with PySpark’. Available at: https://medium.com/data-science/sentiment-analysis-with-pyspark-bc8e83f80c35.\n",
        "Koushiki (2024) ‘Building Naive Bayes Classifier from Scratch to Perform Sentiment Analysis’. Available at: https://www.analyticsvidhya.com/blog/2022/03/building-naive-bayes-classifier-from-scratch-to-perform-sentiment-analysis/.\n",
        "Machinelearningplus (2025) ‘PySpark Logistic Regression – How to Build and Evaluate Logistic Regression Models using PySpark MLlib’. Available at: www.machinelearningplus.com/pyspark/pyspark-logistic-regression/.\n",
        "Ribeiro, F.N. et al. (2016) ‘SentiBench - a benchmark comparison of state-of-the-practice sentiment analysis methods’. Available at: https://arxiv.org/abs/1512.01818.\n",
        "Thakur, P. (2022) ‘Sentiment Analysis with Naive Bayes Classifier | NLTK | Python Code | Machine Learning’. Available at: https://medium.com/@preethithakur/undesrtand-naive-bayes-algorithm-in-simple-explanation-with-python-code-part-2-a2b91cbbf637.\n",
        "W3schools (2025) ‘Machine Learning - Logistic Regression’. Available at: https://www.w3schools.com/python/python_ml_logistic_regression.asp.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}